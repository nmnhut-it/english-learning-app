{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfa7 TheLostChapter CMS - All-in-One\n",
        "\n",
        "Tr\u00ecnh qu\u1ea3n l\u00fd n\u1ed9i dung s\u00e1ch n\u00f3i v\u1edbi:\n",
        "\n",
        "| Ch\u1ee9c n\u0103ng | M\u00f4 t\u1ea3 |\n",
        "|-----------|--------|\n",
        "| \ud83c\udf99\ufe0f **Voice Recorder** | Record tr\u1ef1c ti\u1ebfp t\u1eeb browser, l\u1ecdc noise, ch\u1ec9nh volume |\n",
        "| \ud83e\uddd1\u200d\ud83d\udcbb **Voice Cloning** | Clone gi\u1ecdng n\u00f3i t\u1eeb file m\u1eabu (viXTTS) |\n",
        "| \ud83d\udcdd **Content Editor** | Xem v\u00e0 ch\u1ec9nh s\u1eeda n\u1ed9i dung s\u00e1ch |\n",
        "| \ud83d\udd0a **Audio Generation** | T\u1ea1o audio t\u1eeb gi\u1ecdng clone ho\u1eb7c record tr\u1ef1c ti\u1ebfp |\n",
        "| \ud83d\ude80 **GitHub Push** | L\u01b0u thay \u0111\u1ed5i l\u00ean GitHub |\n",
        "\n",
        "## \u26a1 Quick Start\n",
        "1. **Runtime \u2192 Change runtime type \u2192 T4 GPU** (cho voice cloning)\n",
        "2. Th\u00eam `GITHUB_TOKEN` v\u00e0o Colab Secrets (\ud83d\udd11 sidebar)\n",
        "3. **Run All** (Ctrl+F9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83d\udce6 Setup Environment { display-mode: \"form\" }\n",
        "#@markdown ### C\u00e0i \u0111\u1eb7t m\u00f4i tr\u01b0\u1eddng v\u00e0 clone repo\n",
        "\n",
        "GITHUB_USERNAME = \"nmnhut-it\" #@param {type:\"string\"}\n",
        "REPO_NAME = \"english-learning-app\" #@param {type:\"string\"}\n",
        "BRANCH = \"claude/audio-book-app-8dJZq\" #@param {type:\"string\"}\n",
        "\n",
        "import subprocess, sys, os\n",
        "\n",
        "# ========== Install Dependencies ==========\n",
        "print(\"=\"*50)\n",
        "print(\"\ud83d\udce6 Installing dependencies...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n",
        "                \"coqui-tts\", \"torchcodec\", \"soundfile\", \"pydub\", \n",
        "                \"noisereduce\", \"ipywidgets\"], check=True)\n",
        "\n",
        "import torch, json, re, numpy as np, soundfile as sf\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from pydub import AudioSegment\n",
        "from google.colab import userdata, files, output\n",
        "from IPython.display import Audio, display, HTML, Javascript\n",
        "import ipywidgets as widgets\n",
        "import noisereduce as nr\n",
        "\n",
        "HAS_GPU = torch.cuda.is_available()\n",
        "print(f\"\\n\u2705 Installed! GPU: {torch.cuda.get_device_name() if HAS_GPU else 'None (record-only mode)'}\")\n",
        "\n",
        "# ========== Clone Repo ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"\ud83d\udce5 Cloning repository...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "except:\n",
        "    GITHUB_TOKEN = input(\"Enter GitHub token: \")\n",
        "\n",
        "REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "REPO_DIR = Path(f\"/content/{REPO_NAME}\")\n",
        "\n",
        "if REPO_DIR.exists():\n",
        "    os.chdir(REPO_DIR)\n",
        "    subprocess.run([\"git\", \"pull\", \"origin\", BRANCH], check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", \"-b\", BRANCH, REPO_URL, str(REPO_DIR)], check=True)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "subprocess.run([\"git\", \"config\", \"user.email\", \"colab@thelostchapter.app\"])\n",
        "subprocess.run([\"git\", \"config\", \"user.name\", \"TheLostChapter CMS\"])\n",
        "\n",
        "# Setup paths\n",
        "TLC_DIR = REPO_DIR / \"the-lost-chapter\"\n",
        "VOICES_DIR = TLC_DIR / \"voices\"\n",
        "CONTENT_DIR = TLC_DIR / \"content\" / \"books\"\n",
        "VOICES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\u2705 Repository ready at: {REPO_DIR}\")\n",
        "\n",
        "# ========== Store Globals ==========\n",
        "# These will be populated by subsequent cells\n",
        "model = None\n",
        "voice_profiles = {\"vi\": None, \"en\": None}\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"\ud83c\udf89 Setup complete! Choose your workflow below.\")\n",
        "print(\"=\"*50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## \ud83c\udfa4 OPTION A: Record Voice Directly\n",
        "\n",
        "Record audio tr\u1ef1c ti\u1ebfp t\u1eeb browser, kh\u00f4ng c\u1ea7n GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83c\udf99\ufe0f Voice Recorder { display-mode: \"form\" }\n",
        "#@markdown ### Record gi\u1ecdng n\u00f3i tr\u1ef1c ti\u1ebfp t\u1eeb browser\n",
        "#@markdown \n",
        "#@markdown **Tips:**\n",
        "#@markdown - N\u00f3i r\u00f5 r\u00e0ng, \u1edf m\u00f4i tr\u01b0\u1eddng y\u00ean t\u0129nh\n",
        "#@markdown - L\u1ecdc noise s\u1ebd t\u1ef1 \u0111\u1ed9ng \u00e1p d\u1ee5ng\n",
        "#@markdown - Sau khi record, file s\u1ebd l\u01b0u t\u1ea1m th\u1eddi\n",
        "\n",
        "NOISE_REDUCTION = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "VOLUME_BOOST = 1.0 #@param {type:\"slider\", min:0.5, max:2.0, step:0.1}\n",
        "\n",
        "# HTML/JS for recording\n",
        "RECORDER_HTML = '''\n",
        "<div id=\"recorder-container\" style=\"padding: 20px; background: #1e1e1e; border-radius: 10px; color: white; font-family: sans-serif;\">\n",
        "    <h3 style=\"margin-top: 0;\">\ud83c\udf99\ufe0f Voice Recorder</h3>\n",
        "    \n",
        "    <div style=\"margin: 20px 0;\">\n",
        "        <label style=\"display: block; margin-bottom: 10px;\">Record for:</label>\n",
        "        <select id=\"rec-target\" style=\"padding: 10px; font-size: 16px; border-radius: 5px; width: 200px;\">\n",
        "            <option value=\"chapter\">Chapter Audio</option>\n",
        "            <option value=\"voice-vi\">Voice Sample (VI)</option>\n",
        "            <option value=\"voice-en\">Voice Sample (EN)</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    \n",
        "    <div style=\"margin: 20px 0;\">\n",
        "        <label style=\"display: block; margin-bottom: 10px;\">Chapter ID (if recording chapter):</label>\n",
        "        <input type=\"text\" id=\"rec-chapter-id\" value=\"ch01\" style=\"padding: 10px; font-size: 16px; border-radius: 5px; width: 180px;\">\n",
        "        <select id=\"rec-lang\" style=\"padding: 10px; font-size: 16px; border-radius: 5px; margin-left: 10px;\">\n",
        "            <option value=\"vi\">Vietnamese</option>\n",
        "            <option value=\"en\">English</option>\n",
        "        </select>\n",
        "    </div>\n",
        "    \n",
        "    <div style=\"display: flex; gap: 10px; margin: 20px 0;\">\n",
        "        <button id=\"btn-record\" onclick=\"toggleRecording()\" \n",
        "                style=\"padding: 15px 30px; font-size: 18px; background: #e53935; color: white; border: none; border-radius: 50px; cursor: pointer;\">\n",
        "            \u23fa Start Recording\n",
        "        </button>\n",
        "        <button id=\"btn-play\" onclick=\"playRecording()\" disabled\n",
        "                style=\"padding: 15px 30px; font-size: 18px; background: #444; color: white; border: none; border-radius: 50px; cursor: pointer;\">\n",
        "            \u25b6 Play\n",
        "        </button>\n",
        "        <button id=\"btn-save\" onclick=\"saveRecording()\" disabled\n",
        "                style=\"padding: 15px 30px; font-size: 18px; background: #43a047; color: white; border: none; border-radius: 50px; cursor: pointer;\">\n",
        "            \ud83d\udcbe Save\n",
        "        </button>\n",
        "    </div>\n",
        "    \n",
        "    <div id=\"rec-status\" style=\"margin: 15px 0; padding: 10px; background: #333; border-radius: 5px;\">\n",
        "        Ready to record\n",
        "    </div>\n",
        "    \n",
        "    <div id=\"rec-timer\" style=\"font-size: 48px; font-weight: bold; text-align: center; margin: 20px 0;\">\n",
        "        00:00\n",
        "    </div>\n",
        "    \n",
        "    <audio id=\"rec-audio\" controls style=\"width: 100%; margin-top: 10px; display: none;\"></audio>\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "let mediaRecorder = null;\n",
        "let audioChunks = [];\n",
        "let recordingBlob = null;\n",
        "let timerInterval = null;\n",
        "let startTime = null;\n",
        "\n",
        "async function toggleRecording() {\n",
        "    const btn = document.getElementById(\"btn-record\");\n",
        "    const status = document.getElementById(\"rec-status\");\n",
        "    \n",
        "    if (mediaRecorder && mediaRecorder.state === \"recording\") {\n",
        "        // Stop recording\n",
        "        mediaRecorder.stop();\n",
        "        btn.innerHTML = \"\u23fa Start Recording\";\n",
        "        btn.style.background = \"#e53935\";\n",
        "        status.innerHTML = \"Processing...\";\n",
        "        clearInterval(timerInterval);\n",
        "    } else {\n",
        "        // Start recording\n",
        "        try {\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "            mediaRecorder = new MediaRecorder(stream, { mimeType: \"audio/webm\" });\n",
        "            audioChunks = [];\n",
        "            \n",
        "            mediaRecorder.ondataavailable = (e) => {\n",
        "                audioChunks.push(e.data);\n",
        "            };\n",
        "            \n",
        "            mediaRecorder.onstop = () => {\n",
        "                recordingBlob = new Blob(audioChunks, { type: \"audio/webm\" });\n",
        "                const audioUrl = URL.createObjectURL(recordingBlob);\n",
        "                const audio = document.getElementById(\"rec-audio\");\n",
        "                audio.src = audioUrl;\n",
        "                audio.style.display = \"block\";\n",
        "                document.getElementById(\"btn-play\").disabled = false;\n",
        "                document.getElementById(\"btn-save\").disabled = false;\n",
        "                status.innerHTML = \"\u2705 Recording complete! Click Save to process.\";\n",
        "                stream.getTracks().forEach(track => track.stop());\n",
        "            };\n",
        "            \n",
        "            mediaRecorder.start();\n",
        "            btn.innerHTML = \"\u23f9 Stop Recording\";\n",
        "            btn.style.background = \"#f44336\";\n",
        "            status.innerHTML = \"\ud83d\udd34 Recording...\";\n",
        "            \n",
        "            // Timer\n",
        "            startTime = Date.now();\n",
        "            timerInterval = setInterval(() => {\n",
        "                const elapsed = Math.floor((Date.now() - startTime) / 1000);\n",
        "                const mins = String(Math.floor(elapsed / 60)).padStart(2, \"0\");\n",
        "                const secs = String(elapsed % 60).padStart(2, \"0\");\n",
        "                document.getElementById(\"rec-timer\").innerHTML = `${mins}:${secs}`;\n",
        "            }, 1000);\n",
        "        } catch (err) {\n",
        "            status.innerHTML = \"\u274c Error: \" + err.message;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "function playRecording() {\n",
        "    document.getElementById(\"rec-audio\").play();\n",
        "}\n",
        "\n",
        "async function saveRecording() {\n",
        "    if (!recordingBlob) return;\n",
        "    \n",
        "    const status = document.getElementById(\"rec-status\");\n",
        "    status.innerHTML = \"\ud83d\udcbe Saving...\";\n",
        "    \n",
        "    const target = document.getElementById(\"rec-target\").value;\n",
        "    const chapterId = document.getElementById(\"rec-chapter-id\").value;\n",
        "    const lang = document.getElementById(\"rec-lang\").value;\n",
        "    \n",
        "    // Convert blob to base64\n",
        "    const reader = new FileReader();\n",
        "    reader.readAsDataURL(recordingBlob);\n",
        "    reader.onloadend = () => {\n",
        "        const base64 = reader.result.split(\",\")[1];\n",
        "        google.colab.kernel.invokeFunction(\"notebook.save_recording\", [base64, target, chapterId, lang], {});\n",
        "    };\n",
        "}\n",
        "</script>\n",
        "'''\n",
        "\n",
        "# Python callback for saving\n",
        "def save_recording(base64_audio, target, chapter_id, lang):\n",
        "    import base64\n",
        "    from pydub import AudioSegment\n",
        "    import noisereduce as nr\n",
        "    import soundfile as sf\n",
        "    import io\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcbe Processing recording...\")\n",
        "    print(f\"   Target: {target}\")\n",
        "    print(f\"   Chapter: {chapter_id}\")\n",
        "    print(f\"   Language: {lang}\")\n",
        "    \n",
        "    # Decode base64\n",
        "    audio_bytes = base64.b64decode(base64_audio)\n",
        "    \n",
        "    # Save temp webm\n",
        "    temp_webm = \"/content/temp_recording.webm\"\n",
        "    with open(temp_webm, \"wb\") as f:\n",
        "        f.write(audio_bytes)\n",
        "    \n",
        "    # Convert to wav\n",
        "    audio = AudioSegment.from_file(temp_webm, format=\"webm\")\n",
        "    audio = audio.set_frame_rate(24000).set_channels(1)\n",
        "    \n",
        "    # Apply volume boost\n",
        "    if VOLUME_BOOST != 1.0:\n",
        "        gain_db = 20 * np.log10(VOLUME_BOOST)\n",
        "        audio = audio + gain_db\n",
        "        print(f\"   Volume boost: {VOLUME_BOOST}x ({gain_db:.1f} dB)\")\n",
        "    \n",
        "    # Export to numpy for noise reduction\n",
        "    temp_wav = \"/content/temp_recording.wav\"\n",
        "    audio.export(temp_wav, format=\"wav\")\n",
        "    \n",
        "    # Apply noise reduction\n",
        "    if NOISE_REDUCTION > 0:\n",
        "        data, sr = sf.read(temp_wav)\n",
        "        reduced = nr.reduce_noise(y=data, sr=sr, prop_decrease=NOISE_REDUCTION)\n",
        "        sf.write(temp_wav, reduced, sr)\n",
        "        print(f\"   Noise reduction: {NOISE_REDUCTION*100:.0f}%\")\n",
        "    \n",
        "    # Determine output path\n",
        "    if target == \"voice-vi\":\n",
        "        output_path = VOICES_DIR / \"my-voice-vi.wav\"\n",
        "    elif target == \"voice-en\":\n",
        "        output_path = VOICES_DIR / \"my-voice-en.wav\"\n",
        "    else:\n",
        "        # Chapter audio - need to get book ID\n",
        "        books = list(CONTENT_DIR.iterdir())\n",
        "        if books:\n",
        "            book_dir = books[0]  # Default to first book\n",
        "            audio_dir = book_dir / \"audio\"\n",
        "            audio_dir.mkdir(exist_ok=True)\n",
        "            output_path = audio_dir / f\"{chapter_id}-{lang}.wav\"\n",
        "        else:\n",
        "            output_path = Path(f\"/content/{chapter_id}-{lang}.wav\")\n",
        "    \n",
        "    # Copy to final location\n",
        "    import shutil\n",
        "    shutil.copy(temp_wav, output_path)\n",
        "    \n",
        "    duration = len(AudioSegment.from_wav(str(output_path))) / 1000\n",
        "    print(f\"\\n\u2705 Saved: {output_path}\")\n",
        "    print(f\"   Duration: {duration:.1f}s\")\n",
        "    print(f\"   Size: {output_path.stat().st_size/1024:.1f} KB\")\n",
        "    \n",
        "    return str(output_path)\n",
        "\n",
        "# Register callback\n",
        "output.register_callback('notebook.save_recording', save_recording)\n",
        "\n",
        "# Display recorder\n",
        "display(HTML(RECORDER_HTML))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## \ud83e\uddd1\u200d\ud83d\udcbb OPTION B: Voice Cloning (GPU Required)\n",
        "\n",
        "Clone gi\u1ecdng n\u00f3i t\u1eeb file m\u1eabu \u0111\u1ec3 t\u1ea1o audio t\u1ef1 \u0111\u1ed9ng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83e\udde0 Load viXTTS Model { display-mode: \"form\" }\n",
        "#@markdown ### Load model voice cloning (c\u1ea7n GPU)\n",
        "\n",
        "if not HAS_GPU:\n",
        "    print(\"\u274c Kh\u00f4ng c\u00f3 GPU! Voice cloning c\u1ea7n GPU.\")\n",
        "    print(\"\ud83d\udca1 Tip: Runtime \u2192 Change runtime type \u2192 T4 GPU\")\n",
        "    print(\"\\nHo\u1eb7c s\u1eed d\u1ee5ng Voice Recorder \u1edf Option A \u0111\u1ec3 record tr\u1ef1c ti\u1ebfp.\")\n",
        "else:\n",
        "    print(\"=\"*50)\n",
        "    print(\"\ud83d\ude80 Loading viXTTS model...\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    from huggingface_hub import hf_hub_download\n",
        "    from TTS.tts.configs.xtts_config import XttsConfig\n",
        "    from TTS.tts.models.xtts import Xtts\n",
        "    from TTS.tts.layers.xtts import tokenizer as xtts_tokenizer\n",
        "    \n",
        "    # Patch for Vietnamese\n",
        "    _orig_preprocess = xtts_tokenizer.VoiceBpeTokenizer.preprocess_text\n",
        "    def _patched(self, txt, lang):\n",
        "        if lang == \"vi\":\n",
        "            txt = txt.replace('\"', '')\n",
        "            txt = re.sub(r'\\s+', ' ', txt)\n",
        "            return txt.strip()\n",
        "        return _orig_preprocess(self, txt, lang)\n",
        "    xtts_tokenizer.VoiceBpeTokenizer.preprocess_text = _patched\n",
        "    \n",
        "    MODEL_DIR = Path(\"/content/models/vixtts\")\n",
        "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    for f in [\"config.json\", \"model.pth\", \"vocab.json\"]:\n",
        "        if not (MODEL_DIR / f).exists():\n",
        "            print(f\"  Downloading {f}...\")\n",
        "            hf_hub_download(repo_id=\"capleaf/viXTTS\", filename=f, local_dir=str(MODEL_DIR))\n",
        "        else:\n",
        "            print(f\"  \u2713 {f} (cached)\")\n",
        "    \n",
        "    config = XttsConfig()\n",
        "    config.load_json(str(MODEL_DIR / \"config.json\"))\n",
        "    model = Xtts.init_from_config(config)\n",
        "    model.load_checkpoint(config, checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
        "                          vocab_path=str(MODEL_DIR / \"vocab.json\"))\n",
        "    model.cuda()\n",
        "    print(f\"\\n\u2705 Model loaded on GPU!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83c\udfb5 Clone Voice from Samples { display-mode: \"form\" }\n",
        "#@markdown ### Clone gi\u1ecdng n\u00f3i t\u1eeb file m\u1eabu\n",
        "\n",
        "if model is None:\n",
        "    print(\"\u274c Model ch\u01b0a load! Ch\u1ea1y cell 'Load viXTTS Model' tr\u01b0\u1edbc.\")\n",
        "else:\n",
        "    print(\"=\"*50)\n",
        "    print(\"\ud83c\udfb5 Scanning voice samples...\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Find samples\n",
        "    vi_samples = list(VOICES_DIR.glob('*-vi.*')) + list(VOICES_DIR.glob('*_vi.*')) + list(VOICES_DIR.glob('*vi.wav'))\n",
        "    en_samples = list(VOICES_DIR.glob('*-en.*')) + list(VOICES_DIR.glob('*_en.*')) + list(VOICES_DIR.glob('*en.wav'))\n",
        "    \n",
        "    print(f\"\\n\ud83c\udfb5 Voice samples:\")\n",
        "    print(f\"   VI: {[f.name for f in vi_samples] if vi_samples else '\u274c MISSING'}\")\n",
        "    print(f\"   EN: {[f.name for f in en_samples] if en_samples else '\u274c MISSING'}\")\n",
        "    \n",
        "    def convert_to_wav(input_file, output_name=\"speaker\"):\n",
        "        wav_path = f\"/content/{output_name}.wav\"\n",
        "        ext = Path(input_file).suffix.lower()\n",
        "        \n",
        "        if ext == '.m4a':\n",
        "            audio = AudioSegment.from_file(str(input_file), format='m4a')\n",
        "        elif ext == '.mp3':\n",
        "            audio = AudioSegment.from_mp3(str(input_file))\n",
        "        elif ext == '.wav':\n",
        "            audio = AudioSegment.from_wav(str(input_file))\n",
        "        else:\n",
        "            audio = AudioSegment.from_file(str(input_file))\n",
        "        \n",
        "        audio = audio.set_frame_rate(22050).set_channels(1)\n",
        "        audio.export(wav_path, format=\"wav\")\n",
        "        duration = len(audio) / 1000\n",
        "        print(f\"  \u2713 Converted {ext} \u2192 wav ({duration:.1f}s)\")\n",
        "        return wav_path, duration\n",
        "    \n",
        "    def clone_voice(sample_file, profile_name, lang_code):\n",
        "        profile_file = VOICES_DIR / f\"{profile_name}.pt\"\n",
        "        \n",
        "        if profile_file.exists():\n",
        "            print(f\"\\n\u2705 {lang_code.upper()}: Profile exists ({profile_name}.pt)\")\n",
        "            data = torch.load(profile_file, weights_only=False)\n",
        "            return data[\"gpt_cond_latent\"].cuda(), data[\"speaker_embedding\"].cuda()\n",
        "        \n",
        "        print(f\"\\n\ud83e\uddec {lang_code.upper()}: Cloning from {sample_file.name}...\")\n",
        "        wav_path, duration = convert_to_wav(sample_file, f\"speaker_{lang_code}\")\n",
        "        \n",
        "        if duration < 10:\n",
        "            print(f\"  \u26a0\ufe0f Warning: Audio is only {duration:.1f}s. Recommend 30-60s.\")\n",
        "        \n",
        "        gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=wav_path)\n",
        "        \n",
        "        torch.save({\n",
        "            \"gpt_cond_latent\": gpt_cond_latent.cpu(),\n",
        "            \"speaker_embedding\": speaker_embedding.cpu(),\n",
        "            \"source\": sample_file.name,\n",
        "            \"language\": lang_code,\n",
        "            \"duration\": duration,\n",
        "            \"created\": datetime.now().isoformat(),\n",
        "            \"model\": \"viXTTS\"\n",
        "        }, profile_file)\n",
        "        \n",
        "        print(f\"  \u2705 Saved as {profile_name}.pt\")\n",
        "        return gpt_cond_latent.cuda(), speaker_embedding.cuda()\n",
        "    \n",
        "    # Clone voices\n",
        "    if vi_samples:\n",
        "        voice_profiles[\"vi\"] = clone_voice(vi_samples[0], \"default-vi\", \"vi\")\n",
        "    \n",
        "    if en_samples:\n",
        "        voice_profiles[\"en\"] = clone_voice(en_samples[0], \"default-en\", \"en\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"\ud83c\udfb5 Voice profiles ready!\")\n",
        "    print(\"=\"*50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## \ud83d\udcdd Content Editor\n",
        "\n",
        "Xem v\u00e0 ch\u1ec9nh s\u1eeda n\u1ed9i dung s\u00e1ch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83d\udcda Browse Books { display-mode: \"form\" }\n",
        "#@markdown ### Xem danh s\u00e1ch s\u00e1ch v\u00e0 chapters\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"\ud83d\udcda Available Books\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "books_data = {}\n",
        "\n",
        "for book_dir in sorted(CONTENT_DIR.iterdir()):\n",
        "    if not book_dir.is_dir():\n",
        "        continue\n",
        "    \n",
        "    book_json = book_dir / \"book.json\"\n",
        "    if book_json.exists():\n",
        "        with open(book_json, encoding='utf-8') as f:\n",
        "            book = json.load(f)\n",
        "        \n",
        "        books_data[book_dir.name] = book\n",
        "        \n",
        "        print(f\"\\n\ud83d\udcd6 {book['title']}\")\n",
        "        print(f\"   ID: {book_dir.name}\")\n",
        "        print(f\"   Language: {book.get('language', 'vi')}\")\n",
        "        print(f\"   Chapters: {len(book.get('chapters', []))}\")\n",
        "        \n",
        "        for ch_id in book.get('chapters', []):\n",
        "            ch_file = book_dir / \"chapters\" / f\"{ch_id}.json\"\n",
        "            if ch_file.exists():\n",
        "                with open(ch_file, encoding='utf-8') as f:\n",
        "                    ch = json.load(f)\n",
        "                print(f\"      - {ch_id}: {ch.get('title', 'Untitled')}\")\n",
        "\n",
        "if not books_data:\n",
        "    print(\"\u274c No books found!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \u270f\ufe0f Edit Chapter Content { display-mode: \"form\" }\n",
        "#@markdown ### Ch\u1ec9nh s\u1eeda n\u1ed9i dung chapter\n",
        "\n",
        "BOOK_ID = \"gentle-mind\" #@param {type:\"string\"}\n",
        "CHAPTER_ID = \"ch01\" #@param {type:\"string\"}\n",
        "\n",
        "chapter_file = CONTENT_DIR / BOOK_ID / \"chapters\" / f\"{CHAPTER_ID}.json\"\n",
        "\n",
        "if not chapter_file.exists():\n",
        "    print(f\"\u274c Chapter not found: {chapter_file}\")\n",
        "else:\n",
        "    with open(chapter_file, encoding='utf-8') as f:\n",
        "        chapter_data = json.load(f)\n",
        "    \n",
        "    print(f\"\ud83d\udcd6 Editing: {chapter_data.get('title', CHAPTER_ID)}\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # Create widgets for each section\n",
        "    section_widgets = []\n",
        "    \n",
        "    for i, section in enumerate(chapter_data.get('sections', [])):\n",
        "        section_type = section.get('type', 'unknown')\n",
        "        section_lang = section.get('lang', '')\n",
        "        \n",
        "        if section_type == 'markdown':\n",
        "            content = section.get('content', '')\n",
        "            \n",
        "            # Header\n",
        "            header = widgets.HTML(\n",
        "                value=f\"<h4 style='margin: 20px 0 10px 0;'>\ud83d\udcc4 Section {i+1} ({section_type}) {f'[{section_lang.upper()}]' if section_lang else ''}</h4>\"\n",
        "            )\n",
        "            \n",
        "            # Text area\n",
        "            textarea = widgets.Textarea(\n",
        "                value=content,\n",
        "                layout=widgets.Layout(width='100%', height='200px'),\n",
        "                description='',\n",
        "            )\n",
        "            textarea.section_index = i\n",
        "            section_widgets.append((header, textarea, section_lang))\n",
        "            \n",
        "        elif section_type == 'exercise':\n",
        "            ex_id = section.get('id', f'ex{i}')\n",
        "            ex_type = section.get('exerciseType', 'unknown')\n",
        "            question = section.get('question', '')\n",
        "            \n",
        "            header = widgets.HTML(\n",
        "                value=f\"<h4 style='margin: 20px 0 10px 0;'>\ud83e\udde9 Section {i+1} (exercise: {ex_type})</h4>\"\n",
        "            )\n",
        "            \n",
        "            info = widgets.HTML(\n",
        "                value=f\"<p style='color: #666;'>ID: {ex_id}<br>Question: {question}</p>\"\n",
        "            )\n",
        "            section_widgets.append((header, info, None))\n",
        "    \n",
        "    # Save button\n",
        "    save_button = widgets.Button(\n",
        "        description='\ud83d\udcbe Save Changes',\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='200px', height='40px')\n",
        "    )\n",
        "    \n",
        "    status_output = widgets.Output()\n",
        "    \n",
        "    def on_save_click(b):\n",
        "        with status_output:\n",
        "            status_output.clear_output()\n",
        "            print(\"\ud83d\udcbe Saving...\")\n",
        "            \n",
        "            # Update chapter data from widgets\n",
        "            for header, widget, lang in section_widgets:\n",
        "                if hasattr(widget, 'section_index'):\n",
        "                    idx = widget.section_index\n",
        "                    chapter_data['sections'][idx]['content'] = widget.value\n",
        "            \n",
        "            # Write back to file\n",
        "            with open(chapter_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(chapter_data, f, ensure_ascii=False, indent=2)\n",
        "            \n",
        "            print(f\"\u2705 Saved to {chapter_file.name}\")\n",
        "    \n",
        "    save_button.on_click(on_save_click)\n",
        "    \n",
        "    # Display all widgets\n",
        "    for header, widget, lang in section_widgets:\n",
        "        display(header)\n",
        "        display(widget)\n",
        "    \n",
        "    display(widgets.HBox([save_button]))\n",
        "    display(status_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## \ud83d\udd0a Audio Generation\n",
        "\n",
        "T\u1ea1o audio t\u1eeb n\u1ed9i dung s\u00e1ch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83c\udfb5 Generate Audio with Cloned Voice { display-mode: \"form\" }\n",
        "#@markdown ### T\u1ea1o audio t\u1eeb gi\u1ecdng clone\n",
        "\n",
        "BOOK_ID = \"gentle-mind\" #@param {type:\"string\"}\n",
        "SKIP_EXISTING = True #@param {type:\"boolean\"}\n",
        "GENERATE_VI = True #@param {type:\"boolean\"}\n",
        "GENERATE_EN = True #@param {type:\"boolean\"}\n",
        "\n",
        "if model is None:\n",
        "    print(\"\u274c Model ch\u01b0a load! Ch\u1ea1y 'Load viXTTS Model' tr\u01b0\u1edbc.\")\n",
        "else:\n",
        "    # Load voice profiles\n",
        "    print(\"=\"*50)\n",
        "    print(\"\ud83c\udfb5 Loading voice profiles...\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    vi_profile = VOICES_DIR / \"default-vi.pt\"\n",
        "    en_profile = VOICES_DIR / \"default-en.pt\"\n",
        "    \n",
        "    gpt_vi, spk_vi, gpt_en, spk_en = None, None, None, None\n",
        "    \n",
        "    if GENERATE_VI and vi_profile.exists():\n",
        "        vi_data = torch.load(vi_profile, weights_only=False)\n",
        "        gpt_vi = vi_data[\"gpt_cond_latent\"].cuda()\n",
        "        spk_vi = vi_data[\"speaker_embedding\"].cuda()\n",
        "        print(f\"\u2705 VI: Loaded\")\n",
        "    elif GENERATE_VI:\n",
        "        print(\"\u274c VI: No profile found\")\n",
        "        GENERATE_VI = False\n",
        "    \n",
        "    if GENERATE_EN and en_profile.exists():\n",
        "        en_data = torch.load(en_profile, weights_only=False)\n",
        "        gpt_en = en_data[\"gpt_cond_latent\"].cuda()\n",
        "        spk_en = en_data[\"speaker_embedding\"].cuda()\n",
        "        print(f\"\u2705 EN: Loaded\")\n",
        "    elif GENERATE_EN:\n",
        "        print(\"\u274c EN: No profile found\")\n",
        "        GENERATE_EN = False\n",
        "    \n",
        "    if not GENERATE_VI and not GENERATE_EN:\n",
        "        print(\"\u274c No voice profiles! Clone voice first.\")\n",
        "    else:\n",
        "        # Setup directories\n",
        "        BOOK_DIR = CONTENT_DIR / BOOK_ID\n",
        "        AUDIO_DIR = BOOK_DIR / \"audio\"\n",
        "        AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        def extract_text_by_lang(sections, target_lang):\n",
        "            texts = []\n",
        "            for section in sections:\n",
        "                if section.get('type') != 'markdown':\n",
        "                    continue\n",
        "                if section.get('lang', '') == target_lang:\n",
        "                    content = section.get('content', '')\n",
        "                    lines = []\n",
        "                    for line in content.split('\\n'):\n",
        "                        line = line.strip()\n",
        "                        if line in ['---', '']: \n",
        "                            continue\n",
        "                        if line.startswith('#'):\n",
        "                            lines.append(line.lstrip('#').strip())\n",
        "                        else:\n",
        "                            lines.append(line)\n",
        "                    texts.append(' '.join(lines))\n",
        "            return ' '.join(texts)\n",
        "        \n",
        "        def generate_audio(text, output_path, lang, gpt_cond, speaker_emb):\n",
        "            sentences = [s.strip() for s in re.split(r'[.!?]', text) if s.strip() and len(s.strip()) > 3]\n",
        "            if not sentences:\n",
        "                return 0\n",
        "            \n",
        "            all_audio, timestamps = [], []\n",
        "            silence = np.zeros(int(24000 * 0.5))\n",
        "            current_time = 0.0\n",
        "            \n",
        "            for i, sentence in enumerate(sentences):\n",
        "                display_text = sentence[:50] + \"...\" if len(sentence) > 50 else sentence\n",
        "                print(f\"  [{i+1}/{len(sentences)}] {display_text}\")\n",
        "                \n",
        "                out = model.inference(sentence + \".\", lang, gpt_cond, speaker_emb, temperature=0.7)\n",
        "                audio_data = out[\"wav\"]\n",
        "                \n",
        "                duration = len(audio_data) / 24000\n",
        "                timestamps.append({\"start\": round(current_time, 2), \"end\": round(current_time + duration, 2), \"text\": sentence})\n",
        "                current_time += duration + 0.5\n",
        "                \n",
        "                all_audio.extend([audio_data, silence])\n",
        "            \n",
        "            combined = np.concatenate(all_audio)\n",
        "            sf.write(str(output_path), combined, 24000)\n",
        "            \n",
        "            with open(output_path.with_suffix('.json'), 'w', encoding='utf-8') as f:\n",
        "                json.dump(timestamps, f, ensure_ascii=False, indent=2)\n",
        "            \n",
        "            return len(combined) / 24000\n",
        "        \n",
        "        # Load book\n",
        "        with open(BOOK_DIR / \"book.json\") as f:\n",
        "            book = json.load(f)\n",
        "        \n",
        "        print(f\"\\n\ud83d\udcd6 Book: {book['title']}\")\n",
        "        print(f\"\ud83d\udcd1 Chapters: {book['chapters']}\")\n",
        "        \n",
        "        generated, skipped = 0, 0\n",
        "        \n",
        "        for chapter_id in book['chapters']:\n",
        "            chapter_file = BOOK_DIR / \"chapters\" / f\"{chapter_id}.json\"\n",
        "            with open(chapter_file) as f:\n",
        "                chapter = json.load(f)\n",
        "            \n",
        "            print(f\"\\n{'='*40}\")\n",
        "            print(f\"\ud83d\udcd6 {chapter_id}: {chapter['title']}\")\n",
        "            \n",
        "            sections = chapter.get('sections', [])\n",
        "            \n",
        "            if GENERATE_VI:\n",
        "                output_vi = AUDIO_DIR / f\"{chapter_id}-vi.wav\"\n",
        "                if SKIP_EXISTING and output_vi.exists():\n",
        "                    print(f\"\u23ed\ufe0f {chapter_id}-vi.wav: exists\")\n",
        "                    skipped += 1\n",
        "                else:\n",
        "                    vi_text = extract_text_by_lang(sections, \"vi\")\n",
        "                    if vi_text.strip():\n",
        "                        print(f\"\\n\ud83c\uddfb\ud83c\uddf3 Generating Vietnamese...\")\n",
        "                        duration = generate_audio(vi_text, output_vi, \"vi\", gpt_vi, spk_vi)\n",
        "                        print(f\"  \u2705 {output_vi.name} ({duration:.1f}s)\")\n",
        "                        generated += 1\n",
        "            \n",
        "            if GENERATE_EN:\n",
        "                output_en = AUDIO_DIR / f\"{chapter_id}-en.wav\"\n",
        "                if SKIP_EXISTING and output_en.exists():\n",
        "                    print(f\"\u23ed\ufe0f {chapter_id}-en.wav: exists\")\n",
        "                    skipped += 1\n",
        "                else:\n",
        "                    en_text = extract_text_by_lang(sections, \"en\")\n",
        "                    if en_text.strip():\n",
        "                        print(f\"\\n\ud83c\uddfa\ud83c\uddf8 Generating English...\")\n",
        "                        duration = generate_audio(en_text, output_en, \"en\", gpt_en, spk_en)\n",
        "                        print(f\"  \u2705 {output_en.name} ({duration:.1f}s)\")\n",
        "                        generated += 1\n",
        "        \n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"\ud83d\udcca Summary: {generated} generated, {skipped} skipped\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83d\udd0a Preview Audio { display-mode: \"form\" }\n",
        "\n",
        "BOOK_ID = \"gentle-mind\" #@param {type:\"string\"}\n",
        "CHAPTER = \"ch01\" #@param [\"ch01\", \"ch02\", \"ch03\"]\n",
        "LANGUAGE = \"vi\" #@param [\"vi\", \"en\"]\n",
        "\n",
        "audio_file = CONTENT_DIR / BOOK_ID / \"audio\" / f\"{CHAPTER}-{LANGUAGE}.wav\"\n",
        "\n",
        "if audio_file.exists():\n",
        "    print(f\"\ud83d\udd0a Playing: {audio_file.name}\")\n",
        "    display(Audio(str(audio_file)))\n",
        "else:\n",
        "    print(f\"\u274c Not found: {audio_file}\")\n",
        "    print(f\"\\nAvailable files:\")\n",
        "    audio_dir = audio_file.parent\n",
        "    if audio_dir.exists():\n",
        "        for f in sorted(audio_dir.glob(\"*.wav\")):\n",
        "            print(f\"   - {f.name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## \ud83d\ude80 Push to GitHub\n",
        "\n",
        "L\u01b0u t\u1ea5t c\u1ea3 thay \u0111\u1ed5i l\u00ean GitHub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83d\ude80 Commit & Push Changes { display-mode: \"form\" }\n",
        "#@markdown ### Push t\u1ea5t c\u1ea3 thay \u0111\u1ed5i l\u00ean GitHub\n",
        "\n",
        "COMMIT_MESSAGE = \"Update content and audio\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"\ud83d\udcca Git Status\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# Show status\n",
        "result = subprocess.run([\"git\", \"status\", \"--short\"], capture_output=True, text=True)\n",
        "if result.stdout.strip():\n",
        "    print(result.stdout)\n",
        "else:\n",
        "    print(\"\u2705 No changes to commit.\")\n",
        "\n",
        "# Add all changes\n",
        "subprocess.run([\"git\", \"add\", \"the-lost-chapter/\"])\n",
        "\n",
        "# Check if there are staged changes\n",
        "result = subprocess.run([\"git\", \"diff\", \"--cached\", \"--quiet\"])\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n\u26a0 Nothing to commit.\")\n",
        "else:\n",
        "    print(f\"\\n\ud83d\udcdd Committing: {COMMIT_MESSAGE}\")\n",
        "    subprocess.run([\"git\", \"commit\", \"-m\", COMMIT_MESSAGE])\n",
        "    \n",
        "    print(f\"\\n\ud83d\ude80 Pushing to {BRANCH}...\")\n",
        "    result = subprocess.run([\"git\", \"push\", \"origin\", BRANCH], capture_output=True, text=True)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        print(f\"\u2705 Pushed successfully!\")\n",
        "        print(f\"\\n\ud83d\udd17 View at: https://github.com/{GITHUB_USERNAME}/{REPO_NAME}/tree/{BRANCH}\")\n",
        "    else:\n",
        "        print(f\"\u274c Push failed:\")\n",
        "        print(result.stderr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83d\udcc4 View Recent Commits { display-mode: \"form\" }\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "result = subprocess.run([\"git\", \"log\", \"--oneline\", \"-10\"], capture_output=True, text=True)\n",
        "print(\"\ud83d\udcc4 Recent commits:\")\n",
        "print(result.stdout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## \ud83d\udce4 Upload Voice Samples\n",
        "\n",
        "Upload file voice m\u1eabu n\u1ebfu ch\u01b0a c\u00f3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#@title \ud83d\udce4 Upload Voice Samples { display-mode: \"form\" }\n",
        "#@markdown ### Upload voice samples t\u1eeb m\u00e1y t\u00ednh\n",
        "\n",
        "print(\"\ud83d\udce4 Upload your voice samples:\")\n",
        "print(\"   - my-voice-vi.m4a (30-60 gi\u00e2y ti\u1ebfng Vi\u1ec7t)\")\n",
        "print(\"   - my-voice-en.m4a (30-60 seconds English)\")\n",
        "print()\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    import shutil\n",
        "    for filename, content in uploaded.items():\n",
        "        # Auto-rename\n",
        "        if 'vi' in filename.lower() or 'viet' in filename.lower():\n",
        "            new_name = \"my-voice-vi\" + Path(filename).suffix\n",
        "        elif 'en' in filename.lower() or 'eng' in filename.lower():\n",
        "            new_name = \"my-voice-en\" + Path(filename).suffix\n",
        "        else:\n",
        "            new_name = filename\n",
        "        \n",
        "        dest = VOICES_DIR / new_name\n",
        "        shutil.copy(filename, dest)\n",
        "        print(f\"\u2705 Saved: {dest}\")\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcc1 Files in voices/:\")\n",
        "    for f in VOICES_DIR.iterdir():\n",
        "        print(f\"   - {f.name}\")\n",
        "else:\n",
        "    print(\"\u26a0 No files uploaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
