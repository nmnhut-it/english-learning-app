{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéß One-Click Audio Generator\n",
        "\n",
        "Generate audio for **Tr√≠ Nh·ªõ D·ªãu D√†ng** with your cloned voice.\n",
        "\n",
        "## ‚ö° Quick Start\n",
        "1. **Runtime ‚Üí Change runtime type ‚Üí T4 GPU**\n",
        "2. Add `GITHUB_TOKEN` to Colab Secrets (üîë sidebar)\n",
        "3. **Run All** (Ctrl+F9)\n",
        "\n",
        "That's it! ‚òï"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title ‚ö° ONE CLICK - Run Everything { display-mode: \"form\" }\n",
        "#@markdown This cell does everything automatically:\n",
        "#@markdown 1. Install dependencies\n",
        "#@markdown 2. Clone repo & load voice profile\n",
        "#@markdown 3. Generate audio for all chapters\n",
        "#@markdown 4. Push to GitHub\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Settings\n",
        "BOOK_ID = \"gentle-mind\" #@param {type:\"string\"}\n",
        "VOICE_PROFILE = \"default\" #@param {type:\"string\"}\n",
        "GITHUB_USERNAME = \"nmnhut-it\" #@param {type:\"string\"}\n",
        "REPO_NAME = \"english-learning-app\" #@param {type:\"string\"}\n",
        "BRANCH = \"main\" #@param {type:\"string\"}\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# ========== STEP 1: Install ==========\n",
        "print(\"=\"*50)\n",
        "print(\"üì¶ STEP 1: Installing dependencies...\")\n",
        "print(\"=\"*50)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n",
        "                \"coqui-tts\", \"torchcodec\", \"soundfile\", \"pydub\"], check=True)\n",
        "\n",
        "import torch\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from google.colab import userdata\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "print(f\"‚úÖ Installed! GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'None'}\")\n",
        "\n",
        "# ========== STEP 2: Clone Repo ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üì• STEP 2: Cloning repository...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "except:\n",
        "    GITHUB_TOKEN = input(\"Enter GitHub token: \")\n",
        "\n",
        "REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "REPO_DIR = Path(f\"/content/{REPO_NAME}\")\n",
        "\n",
        "if REPO_DIR.exists():\n",
        "    os.chdir(REPO_DIR)\n",
        "    subprocess.run([\"git\", \"pull\", \"origin\", BRANCH], check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", \"-b\", BRANCH, REPO_URL, str(REPO_DIR)], check=True)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "subprocess.run([\"git\", \"config\", \"user.email\", \"colab@thelostchapter.app\"])\n",
        "subprocess.run([\"git\", \"config\", \"user.name\", \"TheLostChapter CMS\"])\n",
        "\n",
        "CONTENT_DIR = REPO_DIR / \"the-lost-chapter\" / \"content\" / \"books\"\n",
        "VOICES_DIR = REPO_DIR / \"the-lost-chapter\" / \"voices\"\n",
        "BOOK_DIR = CONTENT_DIR / BOOK_ID\n",
        "AUDIO_DIR = BOOK_DIR / \"audio\"\n",
        "AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"‚úÖ Repository ready!\")\n",
        "\n",
        "# ========== STEP 3: Load Model ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ STEP 3: Loading viXTTS model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.tts.layers.xtts import tokenizer as xtts_tokenizer\n",
        "\n",
        "# Patch for Vietnamese\n",
        "_orig_preprocess = xtts_tokenizer.VoiceBpeTokenizer.preprocess_text\n",
        "def _patched(self, txt, lang):\n",
        "    if lang == \"vi\":\n",
        "        txt = txt.replace('\"', '')\n",
        "        txt = re.sub(r'\\s+', ' ', txt)\n",
        "        return txt.strip()\n",
        "    return _orig_preprocess(self, txt, lang)\n",
        "xtts_tokenizer.VoiceBpeTokenizer.preprocess_text = _patched\n",
        "\n",
        "MODEL_DIR = Path(\"/content/models/vixtts\")\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "for f in [\"config.json\", \"model.pth\", \"vocab.json\"]:\n",
        "    if not (MODEL_DIR / f).exists():\n",
        "        hf_hub_download(repo_id=\"capleaf/viXTTS\", filename=f, local_dir=str(MODEL_DIR))\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(str(MODEL_DIR / \"config.json\"))\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(config, checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
        "                      vocab_path=str(MODEL_DIR / \"vocab.json\"))\n",
        "model.cuda()\n",
        "print(f\"‚úÖ Model loaded on GPU!\")\n",
        "\n",
        "# ========== STEP 4: Load Voice ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üé§ STEP 4: Loading voice profile...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "voice_file = VOICES_DIR / f\"{VOICE_PROFILE}.pt\"\n",
        "if voice_file.exists():\n",
        "    voice_data = torch.load(voice_file, weights_only=False)\n",
        "    gpt_cond_latent = voice_data[\"gpt_cond_latent\"].cuda()\n",
        "    speaker_embedding = voice_data[\"speaker_embedding\"].cuda()\n",
        "    print(f\"‚úÖ Voice profile loaded: {VOICE_PROFILE}\")\n",
        "    print(f\"   Created: {voice_data.get('created', 'unknown')}\")\n",
        "else:\n",
        "    print(f\"‚ùå Voice profile not found: {voice_file}\")\n",
        "    print(f\"\\nAvailable profiles: {[f.stem for f in VOICES_DIR.glob('*.pt')]}\")\n",
        "    print(\"\\nPlease upload a voice sample to create one.\")\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        from pydub import AudioSegment\n",
        "        uploaded_file = list(uploaded.keys())[0]\n",
        "        if uploaded_file.endswith('.mp3'):\n",
        "            audio = AudioSegment.from_mp3(uploaded_file)\n",
        "            wav_path = \"/content/speaker.wav\"\n",
        "            audio.set_frame_rate(22050).set_channels(1).export(wav_path, format=\"wav\")\n",
        "        else:\n",
        "            wav_path = uploaded_file\n",
        "        gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=wav_path)\n",
        "        # Save profile\n",
        "        VOICES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        torch.save({\n",
        "            \"gpt_cond_latent\": gpt_cond_latent.cpu(),\n",
        "            \"speaker_embedding\": speaker_embedding.cpu(),\n",
        "            \"source\": uploaded_file,\n",
        "            \"created\": datetime.now().isoformat()\n",
        "        }, voice_file)\n",
        "        print(f\"‚úÖ Voice cloned and saved as: {VOICE_PROFILE}\")\n",
        "\n",
        "# ========== STEP 5: Generate Audio ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéµ STEP 5: Generating audio for all chapters...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def extract_vietnamese(text):\n",
        "    \"\"\"Extract Vietnamese text from bilingual content\"\"\"\n",
        "    lines = []\n",
        "    for line in text.split('\\n'):\n",
        "        line = line.strip()\n",
        "        # Skip English (italic)\n",
        "        if line.startswith('*') and line.endswith('*'):\n",
        "            continue\n",
        "        # Skip decorators\n",
        "        if line in ['---', ''] or line.startswith('#'):\n",
        "            if line.startswith('#'):\n",
        "                clean = line.lstrip('#').strip()\n",
        "                if '|' in clean:\n",
        "                    clean = clean.split('|')[0].strip()\n",
        "                if clean:\n",
        "                    lines.append(clean)\n",
        "            continue\n",
        "        # Get Vietnamese part\n",
        "        if '|' in line:\n",
        "            line = line.split('|')[0].strip()\n",
        "        if line:\n",
        "            lines.append(line)\n",
        "    return ' '.join(lines)\n",
        "\n",
        "def generate_audio(text, output_path, pause=0.5):\n",
        "    \"\"\"Generate audio with timestamps\"\"\"\n",
        "    sentences = [s.strip() for s in re.split(r'[.!?]', text) if s.strip()]\n",
        "    \n",
        "    all_audio = []\n",
        "    silence = np.zeros(int(24000 * pause))\n",
        "    timestamps = []\n",
        "    current_time = 0.0\n",
        "    \n",
        "    for i, sentence in enumerate(sentences):\n",
        "        if len(sentence) < 3:\n",
        "            continue\n",
        "        print(f\"  [{i+1}/{len(sentences)}] {sentence[:40]}...\")\n",
        "        out = model.inference(sentence + \".\", \"vi\", gpt_cond_latent, speaker_embedding, temperature=0.7)\n",
        "        audio_data = out[\"wav\"]\n",
        "        \n",
        "        duration = len(audio_data) / 24000\n",
        "        timestamps.append({\n",
        "            \"start\": round(current_time, 2),\n",
        "            \"end\": round(current_time + duration, 2),\n",
        "            \"text\": sentence\n",
        "        })\n",
        "        current_time += duration + pause\n",
        "        \n",
        "        all_audio.append(audio_data)\n",
        "        all_audio.append(silence)\n",
        "    \n",
        "    combined = np.concatenate(all_audio)\n",
        "    sf.write(str(output_path), combined, 24000)\n",
        "    \n",
        "    # Save timestamps\n",
        "    ts_path = output_path.with_suffix('.json')\n",
        "    with open(ts_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(timestamps, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    return len(combined) / 24000\n",
        "\n",
        "# Load book\n",
        "with open(BOOK_DIR / \"book.json\") as f:\n",
        "    book = json.load(f)\n",
        "\n",
        "print(f\"\\nüìñ Book: {book['title']}\")\n",
        "print(f\"üìë Chapters: {book['chapters']}\\n\")\n",
        "\n",
        "for chapter_id in book['chapters']:\n",
        "    chapter_file = BOOK_DIR / \"chapters\" / f\"{chapter_id}.json\"\n",
        "    with open(chapter_file) as f:\n",
        "        chapter = json.load(f)\n",
        "    \n",
        "    print(f\"\\n--- {chapter_id}: {chapter['title']} ---\")\n",
        "    \n",
        "    # Collect Vietnamese text\n",
        "    all_text = []\n",
        "    for section in chapter.get('sections', []):\n",
        "        if section.get('type') == 'markdown':\n",
        "            vi_text = extract_vietnamese(section.get('content', ''))\n",
        "            if vi_text:\n",
        "                all_text.append(vi_text)\n",
        "    \n",
        "    full_text = ' '.join(all_text)\n",
        "    if not full_text.strip():\n",
        "        print(\"  ‚ö† No Vietnamese text found, skipping...\")\n",
        "        continue\n",
        "    \n",
        "    output_file = AUDIO_DIR / f\"{chapter_id}-vi.wav\"\n",
        "    duration = generate_audio(full_text, output_file)\n",
        "    print(f\"  ‚úÖ Generated: {output_file.name} ({duration:.1f}s)\")\n",
        "\n",
        "# ========== STEP 6: Push to GitHub ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ STEP 6: Pushing to GitHub...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "subprocess.run([\"git\", \"add\", \"the-lost-chapter/content/\"])\n",
        "subprocess.run([\"git\", \"add\", \"the-lost-chapter/voices/\"])\n",
        "\n",
        "result = subprocess.run([\"git\", \"diff\", \"--cached\", \"--quiet\"])\n",
        "if result.returncode == 0:\n",
        "    print(\"‚ö† No changes to commit.\")\n",
        "else:\n",
        "    subprocess.run([\"git\", \"commit\", \"-m\", f\"Generate audio for {BOOK_ID} with viXTTS\"])\n",
        "    subprocess.run([\"git\", \"push\", \"origin\", BRANCH])\n",
        "    print(f\"‚úÖ Pushed to GitHub!\")\n",
        "\n",
        "# ========== DONE ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéâ ALL DONE!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nüìÅ Audio files: {AUDIO_DIR}\")\n",
        "print(f\"üåê GitHub: https://github.com/{GITHUB_USERNAME}/{REPO_NAME}\")\n",
        "\n",
        "# List generated files\n",
        "print(f\"\\nüìã Generated files:\")\n",
        "for f in sorted(AUDIO_DIR.glob(\"*.wav\")):\n",
        "    size = f.stat().st_size / 1024 / 1024\n",
        "    print(f\"   {f.name} ({size:.1f} MB)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title üîä Preview Audio\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "chapter = \"ch01\" #@param [\"ch01\", \"ch02\", \"ch03\"]\n",
        "\n",
        "audio_file = AUDIO_DIR / f\"{chapter}-vi.wav\"\n",
        "if audio_file.exists():\n",
        "    print(f\"üéß Playing: {audio_file.name}\")\n",
        "    display(Audio(str(audio_file)))\n",
        "else:\n",
        "    print(f\"‚ùå File not found: {audio_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title üì• Download All Audio\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "zip_file = f\"/content/{BOOK_ID}_audio.zip\"\n",
        "shutil.make_archive(zip_file.replace('.zip', ''), 'zip', AUDIO_DIR)\n",
        "files.download(zip_file)\n",
        "print(f\"üì• Downloading: {BOOK_ID}_audio.zip\")"
      ]
    }
  ]
}
