{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": []},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéß One-Click Audio Generator\n",
        "\n",
        "Generate audio for **Tr√≠ Nh·ªõ D·ªãu D√†ng** with your cloned voice.\n",
        "\n",
        "## ‚ö° Quick Start\n",
        "1. **Runtime ‚Üí Change runtime type ‚Üí T4 GPU**\n",
        "2. Add `GITHUB_TOKEN` to Colab Secrets (üîë sidebar)\n",
        "3. **Run All** (Ctrl+F9)\n",
        "\n",
        "Your voice file (`my-voice.m4a`) is already in the repo! ‚úÖ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title ‚ö° ONE CLICK - Run Everything { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Settings\n",
        "BOOK_ID = \"gentle-mind\" #@param {type:\"string\"}\n",
        "VOICE_PROFILE = \"default\" #@param {type:\"string\"}\n",
        "SKIP_EXISTING_AUDIO = True #@param {type:\"boolean\"}\n",
        "GITHUB_USERNAME = \"nmnhut-it\" #@param {type:\"string\"}\n",
        "REPO_NAME = \"english-learning-app\" #@param {type:\"string\"}\n",
        "BRANCH = \"main\" #@param {type:\"string\"}\n",
        "\n",
        "import subprocess, sys, os\n",
        "\n",
        "# ========== STEP 1: Install ==========\n",
        "print(\"=\"*50)\n",
        "print(\"üì¶ STEP 1: Installing dependencies...\")\n",
        "print(\"=\"*50)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \n",
        "                \"coqui-tts\", \"torchcodec\", \"soundfile\", \"pydub\"], check=True)\n",
        "\n",
        "import torch, json, re, numpy as np, soundfile as sf\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from pydub import AudioSegment\n",
        "from google.colab import userdata, files\n",
        "from IPython.display import Audio, display, HTML\n",
        "\n",
        "print(f\"‚úÖ Installed! GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'None'}\")\n",
        "\n",
        "# ========== STEP 2: Clone Repo ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üì• STEP 2: Cloning repository...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "except:\n",
        "    GITHUB_TOKEN = input(\"Enter GitHub token: \")\n",
        "\n",
        "REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "REPO_DIR = Path(f\"/content/{REPO_NAME}\")\n",
        "\n",
        "if REPO_DIR.exists():\n",
        "    os.chdir(REPO_DIR)\n",
        "    subprocess.run([\"git\", \"pull\", \"origin\", BRANCH], check=True)\n",
        "else:\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", \"-b\", BRANCH, REPO_URL, str(REPO_DIR)], check=True)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "subprocess.run([\"git\", \"config\", \"user.email\", \"colab@thelostchapter.app\"])\n",
        "subprocess.run([\"git\", \"config\", \"user.name\", \"TheLostChapter CMS\"])\n",
        "\n",
        "CONTENT_DIR = REPO_DIR / \"the-lost-chapter\" / \"content\" / \"books\"\n",
        "VOICES_DIR = REPO_DIR / \"the-lost-chapter\" / \"voices\"\n",
        "VOICES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "BOOK_DIR = CONTENT_DIR / BOOK_ID\n",
        "AUDIO_DIR = BOOK_DIR / \"audio\"\n",
        "AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Show what we have\n",
        "existing_profiles = list(VOICES_DIR.glob('*.pt'))\n",
        "voice_samples = list(VOICES_DIR.glob('*.m4a')) + list(VOICES_DIR.glob('*.mp3')) + list(VOICES_DIR.glob('*.wav'))\n",
        "print(f\"‚úÖ Repository ready!\")\n",
        "print(f\"üé§ Voice profiles (.pt): {[f.stem for f in existing_profiles] if existing_profiles else 'None'}\")\n",
        "print(f\"üéµ Voice samples: {[f.name for f in voice_samples] if voice_samples else 'None'}\")\n",
        "\n",
        "# ========== STEP 3: Load Model ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ STEP 3: Loading viXTTS model...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.tts.layers.xtts import tokenizer as xtts_tokenizer\n",
        "\n",
        "# Patch for Vietnamese\n",
        "_orig_preprocess = xtts_tokenizer.VoiceBpeTokenizer.preprocess_text\n",
        "def _patched(self, txt, lang):\n",
        "    if lang == \"vi\":\n",
        "        txt = txt.replace('\"', '')\n",
        "        txt = re.sub(r'\\s+', ' ', txt)\n",
        "        return txt.strip()\n",
        "    return _orig_preprocess(self, txt, lang)\n",
        "xtts_tokenizer.VoiceBpeTokenizer.preprocess_text = _patched\n",
        "\n",
        "MODEL_DIR = Path(\"/content/models/vixtts\")\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "for f in [\"config.json\", \"model.pth\", \"vocab.json\"]:\n",
        "    if not (MODEL_DIR / f).exists():\n",
        "        print(f\"  Downloading {f}...\")\n",
        "        hf_hub_download(repo_id=\"capleaf/viXTTS\", filename=f, local_dir=str(MODEL_DIR))\n",
        "    else:\n",
        "        print(f\"  ‚úì {f} (cached)\")\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(str(MODEL_DIR / \"config.json\"))\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(config, checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
        "                      vocab_path=str(MODEL_DIR / \"vocab.json\"))\n",
        "model.cuda()\n",
        "print(f\"‚úÖ Model loaded on GPU!\")\n",
        "\n",
        "# ========== STEP 4: Load or Clone Voice ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üé§ STEP 4: Loading voice profile...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def convert_to_wav(input_file):\n",
        "    \"\"\"Convert any audio format to wav\"\"\"\n",
        "    wav_path = \"/content/speaker.wav\"\n",
        "    ext = Path(input_file).suffix.lower()\n",
        "    \n",
        "    if ext == '.m4a':\n",
        "        audio = AudioSegment.from_file(str(input_file), format='m4a')\n",
        "    elif ext == '.mp3':\n",
        "        audio = AudioSegment.from_mp3(str(input_file))\n",
        "    elif ext == '.wav':\n",
        "        audio = AudioSegment.from_wav(str(input_file))\n",
        "    else:\n",
        "        audio = AudioSegment.from_file(str(input_file))\n",
        "    \n",
        "    audio = audio.set_frame_rate(22050).set_channels(1)\n",
        "    audio.export(wav_path, format=\"wav\")\n",
        "    print(f\"  ‚úì Converted {ext} ‚Üí wav ({len(audio)/1000:.1f}s)\")\n",
        "    return wav_path\n",
        "\n",
        "voice_file = VOICES_DIR / f\"{VOICE_PROFILE}.pt\"\n",
        "\n",
        "if voice_file.exists():\n",
        "    # ===== REUSE EXISTING PROFILE =====\n",
        "    print(f\"‚úÖ Found saved profile: {VOICE_PROFILE}.pt\")\n",
        "    voice_data = torch.load(voice_file, weights_only=False)\n",
        "    gpt_cond_latent = voice_data[\"gpt_cond_latent\"].cuda()\n",
        "    speaker_embedding = voice_data[\"speaker_embedding\"].cuda()\n",
        "    print(f\"   Source: {voice_data.get('source', 'unknown')}\")\n",
        "    print(f\"   Created: {voice_data.get('created', 'unknown')}\")\n",
        "    print(f\"   üîÑ Reusing saved voice (instant!)\")\n",
        "\n",
        "elif voice_samples:\n",
        "    # ===== AUTO-CLONE FROM EXISTING SAMPLE IN REPO =====\n",
        "    sample_file = voice_samples[0]  # Use first found sample\n",
        "    print(f\"üéµ Found voice sample in repo: {sample_file.name}\")\n",
        "    print(f\"   üß¨ Auto-cloning voice...\")\n",
        "    \n",
        "    wav_path = convert_to_wav(sample_file)\n",
        "    gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=wav_path)\n",
        "    \n",
        "    # Save as profile for next time\n",
        "    torch.save({\n",
        "        \"gpt_cond_latent\": gpt_cond_latent.cpu(),\n",
        "        \"speaker_embedding\": speaker_embedding.cpu(),\n",
        "        \"source\": sample_file.name,\n",
        "        \"created\": datetime.now().isoformat(),\n",
        "        \"model\": \"viXTTS\"\n",
        "    }, voice_file)\n",
        "    \n",
        "    gpt_cond_latent = gpt_cond_latent.cuda()\n",
        "    speaker_embedding = speaker_embedding.cuda()\n",
        "    \n",
        "    print(f\"   ‚úÖ Voice cloned and saved as: {VOICE_PROFILE}.pt\")\n",
        "    print(f\"   üìù Next time will be instant!\")\n",
        "\n",
        "else:\n",
        "    # ===== UPLOAD NEW SAMPLE =====\n",
        "    print(f\"‚ö† No voice found. Please upload a sample (mp3/m4a/wav):\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    if not uploaded:\n",
        "        raise Exception(\"‚ùå No file uploaded!\")\n",
        "    \n",
        "    uploaded_file = list(uploaded.keys())[0]\n",
        "    wav_path = convert_to_wav(uploaded_file)\n",
        "    \n",
        "    gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=wav_path)\n",
        "    \n",
        "    torch.save({\n",
        "        \"gpt_cond_latent\": gpt_cond_latent.cpu(),\n",
        "        \"speaker_embedding\": speaker_embedding.cpu(),\n",
        "        \"source\": uploaded_file,\n",
        "        \"created\": datetime.now().isoformat(),\n",
        "        \"model\": \"viXTTS\"\n",
        "    }, voice_file)\n",
        "    \n",
        "    gpt_cond_latent = gpt_cond_latent.cuda()\n",
        "    speaker_embedding = speaker_embedding.cuda()\n",
        "    \n",
        "    print(f\"‚úÖ Voice cloned and saved!\")\n",
        "    os.remove(uploaded_file)\n",
        "\n",
        "# ========== STEP 5: Generate Audio ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéµ STEP 5: Generating audio for all chapters...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def extract_vietnamese(text):\n",
        "    lines = []\n",
        "    for line in text.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if line.startswith('*') and line.endswith('*'): continue\n",
        "        if line in ['---', '']: continue\n",
        "        if line.startswith('#'):\n",
        "            clean = line.lstrip('#').strip()\n",
        "            if '|' in clean: clean = clean.split('|')[0].strip()\n",
        "            if clean: lines.append(clean)\n",
        "            continue\n",
        "        if '|' in line: line = line.split('|')[0].strip()\n",
        "        if line: lines.append(line)\n",
        "    return ' '.join(lines)\n",
        "\n",
        "def generate_audio(text, output_path, pause=0.5):\n",
        "    sentences = [s.strip() for s in re.split(r'[.!?]', text) if s.strip() and len(s.strip()) > 3]\n",
        "    \n",
        "    all_audio, timestamps = [], []\n",
        "    silence = np.zeros(int(24000 * pause))\n",
        "    current_time = 0.0\n",
        "    \n",
        "    for i, sentence in enumerate(sentences):\n",
        "        print(f\"  [{i+1}/{len(sentences)}] {sentence[:40]}...\")\n",
        "        out = model.inference(sentence + \".\", \"vi\", gpt_cond_latent, speaker_embedding, temperature=0.7)\n",
        "        audio_data = out[\"wav\"]\n",
        "        \n",
        "        duration = len(audio_data) / 24000\n",
        "        timestamps.append({\"start\": round(current_time, 2), \"end\": round(current_time + duration, 2), \"text\": sentence})\n",
        "        current_time += duration + pause\n",
        "        \n",
        "        all_audio.extend([audio_data, silence])\n",
        "    \n",
        "    combined = np.concatenate(all_audio)\n",
        "    sf.write(str(output_path), combined, 24000)\n",
        "    \n",
        "    with open(output_path.with_suffix('.json'), 'w', encoding='utf-8') as f:\n",
        "        json.dump(timestamps, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    return len(combined) / 24000\n",
        "\n",
        "with open(BOOK_DIR / \"book.json\") as f:\n",
        "    book = json.load(f)\n",
        "\n",
        "print(f\"\\nüìñ Book: {book['title']}\")\n",
        "print(f\"üìë Chapters: {book['chapters']}\")\n",
        "print(f\"‚è≠Ô∏è Skip existing: {'ON' if SKIP_EXISTING_AUDIO else 'OFF'}\\n\")\n",
        "\n",
        "generated, skipped = 0, 0\n",
        "\n",
        "for chapter_id in book['chapters']:\n",
        "    output_file = AUDIO_DIR / f\"{chapter_id}-vi.wav\"\n",
        "    \n",
        "    if SKIP_EXISTING_AUDIO and output_file.exists():\n",
        "        print(f\"‚è≠Ô∏è {chapter_id}: exists, skipping...\")\n",
        "        skipped += 1\n",
        "        continue\n",
        "    \n",
        "    chapter_file = BOOK_DIR / \"chapters\" / f\"{chapter_id}.json\"\n",
        "    with open(chapter_file) as f:\n",
        "        chapter = json.load(f)\n",
        "    \n",
        "    print(f\"\\n--- {chapter_id}: {chapter['title']} ---\")\n",
        "    \n",
        "    all_text = [extract_vietnamese(s.get('content', '')) \n",
        "                for s in chapter.get('sections', []) if s.get('type') == 'markdown']\n",
        "    full_text = ' '.join(filter(None, all_text))\n",
        "    \n",
        "    if not full_text.strip():\n",
        "        print(\"  ‚ö† No text, skipping...\")\n",
        "        continue\n",
        "    \n",
        "    duration = generate_audio(full_text, output_file)\n",
        "    print(f\"  ‚úÖ {output_file.name} ({duration:.1f}s)\")\n",
        "    generated += 1\n",
        "\n",
        "print(f\"\\nüìä Done: {generated} generated, {skipped} skipped\")\n",
        "\n",
        "# ========== STEP 6: Push ==========\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ STEP 6: Pushing to GitHub...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "subprocess.run([\"git\", \"add\", \"the-lost-chapter/\"])\n",
        "\n",
        "result = subprocess.run([\"git\", \"diff\", \"--cached\", \"--quiet\"])\n",
        "if result.returncode == 0:\n",
        "    print(\"‚ö† No changes to commit.\")\n",
        "else:\n",
        "    subprocess.run([\"git\", \"commit\", \"-m\", f\"Generate audio for {BOOK_ID}\"])\n",
        "    subprocess.run([\"git\", \"push\", \"origin\", BRANCH])\n",
        "    print(f\"‚úÖ Pushed!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéâ ALL DONE!\")\n",
        "print(\"=\"*50)\n",
        "for f in sorted(AUDIO_DIR.glob(\"*.wav\")):\n",
        "    print(f\"   üîä {f.name} ({f.stat().st_size/1024/1024:.1f} MB)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title üîä Preview Audio\n",
        "chapter = \"ch01\" #@param [\"ch01\", \"ch02\", \"ch03\"]\n",
        "audio_file = AUDIO_DIR / f\"{chapter}-vi.wav\"\n",
        "if audio_file.exists():\n",
        "    display(Audio(str(audio_file)))\n",
        "else:\n",
        "    print(f\"‚ùå Not found: {audio_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title üì• Download Audio\n",
        "import shutil\n",
        "shutil.make_archive(f\"/content/{BOOK_ID}_audio\", 'zip', AUDIO_DIR)\n",
        "files.download(f\"/content/{BOOK_ID}_audio.zip\")"
      ]
    }
  ]
}
