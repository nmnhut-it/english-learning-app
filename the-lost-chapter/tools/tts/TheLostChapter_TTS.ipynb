{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéß TheLostChapter - TTS Voice Cloning\n",
        "\n",
        "Generate audiobook narration with your own cloned voice in **Vietnamese** and **English**.\n",
        "\n",
        "## Features\n",
        "- **viXTTS**: Fine-tuned for Vietnamese (best quality)\n",
        "- **XTTS v2**: Multilingual support (18 languages)\n",
        "- **Edge TTS**: Quick generation without cloning\n",
        "\n",
        "## Instructions\n",
        "1. **Runtime > Change runtime type > T4 GPU** (recommended)\n",
        "2. Run cells in order\n",
        "3. Upload your voice sample (6-30 seconds)\n",
        "4. Enter text and generate!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Dependencies"
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "#@title Install TTS and dependencies { display-mode: \"form\" }\n",
        "!pip install -q TTS==0.22.0\n",
        "!pip install -q edge-tts\n",
        "!pip install -q soundfile\n",
        "!pip install -q huggingface_hub\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download viXTTS Model (Vietnamese)\n",
        "\n",
        "This downloads the fine-tuned Vietnamese model (~2GB). Only need to run once per session."
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download viXTTS Model { display-mode: \"form\" }\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "MODEL_DIR = Path(\"/content/models/vixtts\")\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download from capleaf/viXTTS\n",
        "files = [\"config.json\", \"model.pth\", \"vocab.json\"]\n",
        "\n",
        "print(\"Downloading viXTTS model...\")\n",
        "for filename in files:\n",
        "    if not (MODEL_DIR / filename).exists():\n",
        "        print(f\"  Downloading {filename}...\")\n",
        "        hf_hub_download(\n",
        "            repo_id=\"capleaf/viXTTS\",\n",
        "            filename=filename,\n",
        "            local_dir=str(MODEL_DIR),\n",
        "            local_dir_use_symlinks=False\n",
        "        )\n",
        "    else:\n",
        "        print(f\"  {filename} already exists\")\n",
        "\n",
        "print(\"\\n‚úÖ viXTTS model ready!\")"
      ],
      "metadata": {
        "id": "download_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Upload Your Voice Sample\n",
        "\n",
        "Upload a **6-30 second** audio clip of your voice:\n",
        "- Clear speech, no background noise\n",
        "- WAV or MP3 format\n",
        "- Natural speaking pace"
      ],
      "metadata": {
        "id": "upload_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Voice Sample { display-mode: \"form\" }\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, display\n",
        "import shutil\n",
        "\n",
        "print(\"Select your voice sample file (WAV or MP3):\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    SPEAKER_WAV = list(uploaded.keys())[0]\n",
        "    print(f\"\\n‚úÖ Uploaded: {SPEAKER_WAV}\")\n",
        "    print(\"\\nPreview:\")\n",
        "    display(Audio(SPEAKER_WAV))\n",
        "else:\n",
        "    print(\"‚ùå No file uploaded\")"
      ],
      "metadata": {
        "id": "upload_voice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load TTS Model"
      ],
      "metadata": {
        "id": "load_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load viXTTS Model { display-mode: \"form\" }\n",
        "import torch\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "print(\"Loading viXTTS model...\")\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(str(MODEL_DIR / \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
        "    vocab_path=str(MODEL_DIR / \"vocab.json\")\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    print(f\"‚úÖ Model loaded on GPU: {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Running on CPU (slower)\")\n",
        "\n",
        "# Compute speaker embedding from uploaded sample\n",
        "print(f\"\\nProcessing voice sample: {SPEAKER_WAV}\")\n",
        "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=SPEAKER_WAV)\n",
        "print(\"‚úÖ Voice cloned successfully!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Generate Vietnamese Audio üáªüá≥\n",
        "\n",
        "Enter Vietnamese text (10+ words for best quality)."
      ],
      "metadata": {
        "id": "generate_vi_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Vietnamese Audio { display-mode: \"form\" }\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "#@markdown ### Enter Vietnamese text:\n",
        "text_vi = \"Xin ch√†o c√°c b·∫°n, ƒë√¢y l√† gi·ªçng n√≥i c·ªßa t√¥i ƒë∆∞·ª£c t·∫°o b·∫±ng tr√≠ tu·ªá nh√¢n t·∫°o. Ch·∫•t l∆∞·ª£ng √¢m thanh s·∫Ω t·ªët h∆°n v·ªõi c√°c c√¢u d√†i h∆°n m∆∞·ªùi t·ª´.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "temperature = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_filename = \"output_vi.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating audio for: {text_vi[:50]}...\")\n",
        "\n",
        "out = model.inference(\n",
        "    text_vi,\n",
        "    \"vi\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temperature\n",
        ")\n",
        "\n",
        "sf.write(output_filename, out[\"wav\"], 24000)\n",
        "print(f\"\\n‚úÖ Generated: {output_filename}\")\n",
        "print(\"\\nPlayback:\")\n",
        "display(Audio(output_filename))\n",
        "\n",
        "# Download button\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "id": "generate_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generate English Audio üá¨üáß\n",
        "\n",
        "viXTTS also supports English (and 16 other languages)."
      ],
      "metadata": {
        "id": "generate_en_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate English Audio { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Enter English text:\n",
        "text_en = \"Welcome to The Lost Chapter, an interactive audiobook experience. Let me guide you through this amazing story with my voice.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "temperature_en = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_filename_en = \"output_en.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating audio for: {text_en[:50]}...\")\n",
        "\n",
        "out_en = model.inference(\n",
        "    text_en,\n",
        "    \"en\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temperature_en\n",
        ")\n",
        "\n",
        "sf.write(output_filename_en, out_en[\"wav\"], 24000)\n",
        "print(f\"\\n‚úÖ Generated: {output_filename_en}\")\n",
        "print(\"\\nPlayback:\")\n",
        "display(Audio(output_filename_en))\n",
        "\n",
        "files.download(output_filename_en)"
      ],
      "metadata": {
        "id": "generate_en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Batch Generation (Multiple Sentences)\n",
        "\n",
        "Generate audio for multiple paragraphs and combine them."
      ],
      "metadata": {
        "id": "batch_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Batch Generate from Text File { display-mode: \"form\" }\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "#@markdown ### Enter multiple paragraphs (separated by blank lines):\n",
        "batch_text = \"\"\"Ch∆∞∆°ng m·ªôt: Kh·ªüi ƒë·∫ßu.\n",
        "\n",
        "Ng√†y x∆∞a, ·ªü m·ªôt v∆∞∆°ng qu·ªëc xa x√¥i, c√≥ m·ªôt ch√†ng trai tr·∫ª t√™n l√† Minh. Minh lu√¥n m∆° ∆∞·ªõc ƒë∆∞·ª£c kh√°m ph√° th·∫ø gi·ªõi r·ªông l·ªõn ngo√†i kia.\n",
        "\n",
        "M·ªôt ng√†y n·ªç, Minh quy·∫øt ƒë·ªãnh r·ªùi kh·ªèi ng√¥i l√†ng nh·ªè c·ªßa m√¨nh ƒë·ªÉ b·∫Øt ƒë·∫ßu cu·ªôc phi√™u l∆∞u m·ªõi. Ch√†ng mang theo m·ªôt chi·∫øc ba l√¥ nh·ªè v√† tr√°i tim ƒë·∫ßy hy v·ªçng.\"\"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Language:\n",
        "batch_lang = \"vi\" #@param [\"vi\", \"en\"]\n",
        "batch_output = \"batch_output.wav\" #@param {type:\"string\"}\n",
        "\n",
        "# Split into paragraphs\n",
        "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
        "print(f\"Found {len(paragraphs)} paragraphs\")\n",
        "\n",
        "all_audio = []\n",
        "silence = np.zeros(int(24000 * 0.5))  # 0.5s silence between paragraphs\n",
        "\n",
        "for i, para in enumerate(paragraphs):\n",
        "    print(f\"\\nGenerating paragraph {i+1}/{len(paragraphs)}: {para[:40]}...\")\n",
        "    out = model.inference(\n",
        "        para,\n",
        "        batch_lang,\n",
        "        gpt_cond_latent,\n",
        "        speaker_embedding,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    all_audio.append(out[\"wav\"])\n",
        "    all_audio.append(silence)\n",
        "\n",
        "# Combine all audio\n",
        "combined = np.concatenate(all_audio)\n",
        "sf.write(batch_output, combined, 24000)\n",
        "\n",
        "print(f\"\\n‚úÖ Combined audio saved: {batch_output}\")\n",
        "print(f\"Duration: {len(combined)/24000:.1f} seconds\")\n",
        "display(Audio(batch_output))\n",
        "\n",
        "files.download(batch_output)"
      ],
      "metadata": {
        "id": "batch_generate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Edge TTS (No Voice Cloning)\n",
        "\n",
        "Quick generation using Microsoft's neural voices. No GPU required."
      ],
      "metadata": {
        "id": "edge_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Edge TTS - Vietnamese Voices { display-mode: \"form\" }\n",
        "import edge_tts\n",
        "import asyncio\n",
        "\n",
        "#@markdown ### Text:\n",
        "edge_text = \"Xin ch√†o, ƒë√¢y l√† gi·ªçng ƒë·ªçc t·ª´ Microsoft Edge. Ch·∫•t l∆∞·ª£ng kh√° t·ªët v√† kh√¥ng c·∫ßn GPU.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Voice:\n",
        "edge_voice = \"vi-VN-HoaiMyNeural\" #@param [\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\", \"en-US-GuyNeural\", \"en-US-JennyNeural\", \"en-GB-RyanNeural\"]\n",
        "\n",
        "edge_output = \"edge_output.mp3\" #@param {type:\"string\"}\n",
        "\n",
        "async def generate_edge():\n",
        "    communicate = edge_tts.Communicate(edge_text, edge_voice)\n",
        "    await communicate.save(edge_output)\n",
        "\n",
        "await generate_edge()\n",
        "\n",
        "print(f\"‚úÖ Generated: {edge_output}\")\n",
        "display(Audio(edge_output))\n",
        "files.download(edge_output)"
      ],
      "metadata": {
        "id": "edge_tts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Generate from Chapter JSON\n",
        "\n",
        "Upload a TheLostChapter chapter JSON file to generate all audio sections."
      ],
      "metadata": {
        "id": "chapter_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate from Chapter JSON { display-mode: \"form\" }\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"Upload a chapter JSON file:\")\n",
        "chapter_upload = files.upload()\n",
        "\n",
        "if chapter_upload:\n",
        "    chapter_file = list(chapter_upload.keys())[0]\n",
        "    with open(chapter_file, 'r', encoding='utf-8') as f:\n",
        "        chapter = json.load(f)\n",
        "\n",
        "    print(f\"\\nChapter: {chapter.get('title', 'Unknown')}\")\n",
        "\n",
        "    # Find audio sections\n",
        "    audio_sections = [\n",
        "        (i, s) for i, s in enumerate(chapter.get('sections', []))\n",
        "        if s.get('type') == 'audio' and s.get('transcript')\n",
        "    ]\n",
        "\n",
        "    print(f\"Found {len(audio_sections)} audio sections\\n\")\n",
        "\n",
        "    os.makedirs('chapter_audio', exist_ok=True)\n",
        "\n",
        "    for idx, section in audio_sections:\n",
        "        transcript = section['transcript']\n",
        "        lang = section.get('language', 'vi')\n",
        "        output_name = section.get('src', f'section_{idx}.wav')\n",
        "        output_path = f\"chapter_audio/{output_name}\"\n",
        "\n",
        "        print(f\"Generating: {output_name}\")\n",
        "        print(f\"  Text: {transcript[:60]}...\")\n",
        "\n",
        "        out = model.inference(\n",
        "            transcript,\n",
        "            lang,\n",
        "            gpt_cond_latent,\n",
        "            speaker_embedding,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        sf.write(output_path, out[\"wav\"], 24000)\n",
        "        print(f\"  ‚úÖ Saved: {output_path}\\n\")\n",
        "\n",
        "    # Zip and download\n",
        "    !zip -r chapter_audio.zip chapter_audio/\n",
        "    files.download('chapter_audio.zip')\n",
        "    print(\"\\n‚úÖ All audio files zipped and ready for download!\")"
      ],
      "metadata": {
        "id": "chapter_json"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Tips\n",
        "\n",
        "### Vietnamese Quality\n",
        "- Use sentences with **10+ words** for best results\n",
        "- Shorter sentences may produce odd trailing sounds\n",
        "\n",
        "### Voice Sample\n",
        "- **6-30 seconds** of clear speech\n",
        "- No background noise or music\n",
        "- Natural speaking pace\n",
        "\n",
        "### Temperature\n",
        "- **0.5-0.7**: More consistent, robotic\n",
        "- **0.7-0.9**: Natural, expressive\n",
        "- **0.9-1.0**: More variation, may be unstable\n",
        "\n",
        "### Supported Languages\n",
        "Vietnamese (vi), English (en), Spanish (es), French (fr), German (de), Italian (it), Portuguese (pt), Polish (pl), Turkish (tr), Russian (ru), Dutch (nl), Czech (cs), Arabic (ar), Chinese (zh-cn), Japanese (ja), Hungarian (hu), Korean (ko), Hindi (hi)\n",
        "\n",
        "---\n",
        "\n",
        "**TheLostChapter** | [GitHub](https://github.com/nmnhut-it/english-learning-app/tree/main/the-lost-chapter)"
      ],
      "metadata": {
        "id": "tips"
      }
    }
  ]
}
