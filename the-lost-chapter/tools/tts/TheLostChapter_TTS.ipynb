{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§ TheLostChapter - TTS Voice Cloning\n",
        "\n",
        "Generate audiobook narration in **Vietnamese** and **English**.\n",
        "\n",
        "## 2 Options:\n",
        "\n",
        "| Method | Voice Clone | Quality | Speed | GPU |\n",
        "|--------|-------------|---------|-------|-----|\n",
        "| **Edge TTS** | âŒ No | Good | Fast | Not needed |\n",
        "| **viXTTS** | âœ… Yes | Best | Slower | Recommended |\n",
        "\n",
        "## Quick Start\n",
        "- **Just want Vietnamese TTS?** â†’ Skip to **Section A: Edge TTS** (no setup needed)\n",
        "- **Want to clone your voice?** â†’ Go to **Section B: viXTTS**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ…°ï¸ Section A: Edge TTS (Easy - No Voice Cloning)\n",
        "\n",
        "Microsoft's neural voices. High quality, fast, no GPU needed.\n",
        "\n",
        "**Available Vietnamese voices:**\n",
        "- `vi-VN-HoaiMyNeural` - Ná»¯ (Female)\n",
        "- `vi-VN-NamMinhNeural` - Nam (Male)"
      ],
      "metadata": {
        "id": "edge_section"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edge_install"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install Edge TTS { display-mode: \"form\" }\n",
        "!pip install -q edge-tts\n",
        "print(\"âœ… Edge TTS installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Generate Vietnamese Audio (Edge TTS) { display-mode: \"form\" }\n",
        "import edge_tts\n",
        "import asyncio\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Nháº­p vÄƒn báº£n tiáº¿ng Viá»‡t:\n",
        "text = \"Xin chÃ o cÃ¡c báº¡n, Ä‘Ã¢y lÃ  giá»ng Ä‘á»c tá»« Microsoft Edge. Cháº¥t lÆ°á»£ng khÃ¡ tá»‘t vÃ  hoÃ n toÃ n miá»…n phÃ­, khÃ´ng cáº§n GPU hay voice sample.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Chá»n giá»ng Ä‘á»c:\n",
        "voice = \"vi-VN-HoaiMyNeural\" #@param [\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\"]\n",
        "\n",
        "#@markdown ### TÃªn file output:\n",
        "output_file = \"output_vi.mp3\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating with voice: {voice}\")\n",
        "print(f\"Text: {text[:60]}...\\n\")\n",
        "\n",
        "async def generate():\n",
        "    communicate = edge_tts.Communicate(text, voice)\n",
        "    await communicate.save(output_file)\n",
        "\n",
        "await generate()\n",
        "\n",
        "print(f\"âœ… Generated: {output_file}\")\n",
        "print(\"\\nğŸ”Š Playback:\")\n",
        "display(Audio(output_file))\n",
        "\n",
        "print(\"\\nğŸ“¥ Downloading...\")\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "edge_generate_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Generate English Audio (Edge TTS) { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Enter English text:\n",
        "text_en = \"Welcome to The Lost Chapter, an interactive audiobook experience. This voice is generated using Microsoft Edge neural text to speech.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Select voice:\n",
        "voice_en = \"en-US-GuyNeural\" #@param [\"en-US-GuyNeural\", \"en-US-JennyNeural\", \"en-GB-RyanNeural\", \"en-GB-SoniaNeural\", \"en-AU-WilliamNeural\"]\n",
        "\n",
        "output_en = \"output_en.mp3\" #@param {type:\"string\"}\n",
        "\n",
        "async def generate_en():\n",
        "    communicate = edge_tts.Communicate(text_en, voice_en)\n",
        "    await communicate.save(output_en)\n",
        "\n",
        "await generate_en()\n",
        "\n",
        "print(f\"âœ… Generated: {output_en}\")\n",
        "display(Audio(output_en))\n",
        "files.download(output_en)"
      ],
      "metadata": {
        "id": "edge_generate_en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Batch Generate - Multiple Paragraphs (Edge TTS) { display-mode: \"form\" }\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "!pip install -q pydub\n",
        "\n",
        "#@markdown ### Nháº­p nhiá»u Ä‘oáº¡n vÄƒn (cÃ¡ch nhau báº±ng dÃ²ng trá»‘ng):\n",
        "batch_text = \"\"\"ChÆ°Æ¡ng má»™t: Khá»Ÿi Ä‘áº§u.\n",
        "\n",
        "NgÃ y xÆ°a, á»Ÿ má»™t vÆ°Æ¡ng quá»‘c xa xÃ´i, cÃ³ má»™t chÃ ng trai tráº» tÃªn lÃ  Minh. Minh luÃ´n mÆ¡ Æ°á»›c Ä‘Æ°á»£c khÃ¡m phÃ¡ tháº¿ giá»›i rá»™ng lá»›n ngoÃ i kia.\n",
        "\n",
        "Má»™t ngÃ y ná», Minh quyáº¿t Ä‘á»‹nh rá»i khá»i ngÃ´i lÃ ng nhá» cá»§a mÃ¬nh Ä‘á»ƒ báº¯t Ä‘áº§u cuá»™c phiÃªu lÆ°u má»›i. ChÃ ng mang theo má»™t chiáº¿c ba lÃ´ nhá» vÃ  trÃ¡i tim Ä‘áº§y hy vá»ng.\"\"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "batch_voice = \"vi-VN-HoaiMyNeural\" #@param [\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\", \"en-US-GuyNeural\", \"en-US-JennyNeural\"]\n",
        "batch_output = \"batch_output.mp3\" #@param {type:\"string\"}\n",
        "pause_ms = 800 #@param {type:\"integer\"}\n",
        "\n",
        "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
        "print(f\"Found {len(paragraphs)} paragraphs\\n\")\n",
        "\n",
        "os.makedirs('temp_audio', exist_ok=True)\n",
        "audio_segments = []\n",
        "\n",
        "for i, para in enumerate(paragraphs):\n",
        "    print(f\"[{i+1}/{len(paragraphs)}] {para[:50]}...\")\n",
        "    temp_file = f\"temp_audio/para_{i}.mp3\"\n",
        "\n",
        "    async def gen(p, f):\n",
        "        comm = edge_tts.Communicate(p, batch_voice)\n",
        "        await comm.save(f)\n",
        "\n",
        "    await gen(para, temp_file)\n",
        "    audio_segments.append(AudioSegment.from_mp3(temp_file))\n",
        "\n",
        "# Combine with pauses\n",
        "silence = AudioSegment.silent(duration=pause_ms)\n",
        "combined = audio_segments[0]\n",
        "for seg in audio_segments[1:]:\n",
        "    combined += silence + seg\n",
        "\n",
        "combined.export(batch_output, format=\"mp3\")\n",
        "\n",
        "print(f\"\\nâœ… Combined: {batch_output}\")\n",
        "print(f\"Duration: {len(combined)/1000:.1f} seconds\")\n",
        "display(Audio(batch_output))\n",
        "files.download(batch_output)\n",
        "\n",
        "# Cleanup\n",
        "!rm -rf temp_audio"
      ],
      "metadata": {
        "id": "edge_batch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# ğŸ…±ï¸ Section B: viXTTS (Voice Cloning)\n",
        "\n",
        "Clone your voice or use sample voices. Better quality but requires GPU.\n",
        "\n",
        "**âš ï¸ Requirements:**\n",
        "- Runtime > Change runtime type > **T4 GPU**\n",
        "- ~2GB download for model"
      ],
      "metadata": {
        "id": "vixtts_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Install viXTTS Dependencies { display-mode: \"form\" }\n",
        "import sys\n",
        "\n",
        "# Check Python version\n",
        "py_version = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n",
        "print(f\"Python version: {py_version}\")\n",
        "\n",
        "# Install compatible TTS version\n",
        "if sys.version_info.minor >= 12:\n",
        "    print(\"Python 3.12+ detected, using latest TTS...\")\n",
        "    !pip install -q TTS\n",
        "else:\n",
        "    print(\"Installing TTS 0.22.0...\")\n",
        "    !pip install -q TTS==0.22.0\n",
        "\n",
        "!pip install -q soundfile huggingface_hub\n",
        "\n",
        "print(\"\\nâœ… Dependencies installed!\")"
      ],
      "metadata": {
        "id": "vixtts_install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Download viXTTS Model (~2GB) { display-mode: \"form\" }\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pathlib import Path\n",
        "\n",
        "MODEL_DIR = Path(\"/content/models/vixtts\")\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_files = [\"config.json\", \"model.pth\", \"vocab.json\"]\n",
        "\n",
        "print(\"Downloading viXTTS model from capleaf/viXTTS...\")\n",
        "for filename in model_files:\n",
        "    target = MODEL_DIR / filename\n",
        "    if not target.exists():\n",
        "        print(f\"  ğŸ“¥ {filename}...\")\n",
        "        hf_hub_download(\n",
        "            repo_id=\"capleaf/viXTTS\",\n",
        "            filename=filename,\n",
        "            local_dir=str(MODEL_DIR),\n",
        "            local_dir_use_symlinks=False\n",
        "        )\n",
        "    else:\n",
        "        print(f\"  âœ“ {filename} (cached)\")\n",
        "\n",
        "print(\"\\nâœ… viXTTS model ready!\")"
      ],
      "metadata": {
        "id": "vixtts_download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Download Sample Voice (Skip if uploading your own) { display-mode: \"form\" }\n",
        "#@markdown Download a sample Vietnamese voice to use without uploading your own.\n",
        "\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "#@markdown ### Select sample voice:\n",
        "sample_voice = \"vietnamese_female\" #@param [\"vietnamese_female\", \"vietnamese_male\", \"english_female\", \"english_male\"]\n",
        "\n",
        "# Sample voice URLs (from viXTTS demo)\n",
        "SAMPLE_VOICES = {\n",
        "    \"vietnamese_female\": \"https://huggingface.co/spaces/thinhlpg/vixtts-demo/resolve/main/samples/nu-luu-loat.wav\",\n",
        "    \"vietnamese_male\": \"https://huggingface.co/spaces/thinhlpg/vixtts-demo/resolve/main/samples/nam-truyen-cam.wav\",\n",
        "    \"english_female\": \"https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav\",\n",
        "    \"english_male\": \"https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav\",\n",
        "}\n",
        "\n",
        "Path(\"samples\").mkdir(exist_ok=True)\n",
        "SPEAKER_WAV = f\"samples/{sample_voice}.wav\"\n",
        "\n",
        "if not Path(SPEAKER_WAV).exists():\n",
        "    print(f\"Downloading {sample_voice} sample...\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(SAMPLE_VOICES[sample_voice], SPEAKER_WAV)\n",
        "        print(f\"âœ… Downloaded: {SPEAKER_WAV}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Download failed: {e}\")\n",
        "        print(\"Please upload your own voice sample in the next cell.\")\n",
        "else:\n",
        "    print(f\"âœ… Using cached: {SPEAKER_WAV}\")\n",
        "\n",
        "print(f\"\\nğŸ”Š Preview:\")\n",
        "display(Audio(SPEAKER_WAV))"
      ],
      "metadata": {
        "id": "download_sample_voice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. OR Upload Your Own Voice Sample { display-mode: \"form\" }\n",
        "#@markdown Upload 6-30 seconds of clear speech (WAV/MP3).\n",
        "#@markdown **Skip this if you used sample voice above.**\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "print(\"Select your voice sample file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    SPEAKER_WAV = list(uploaded.keys())[0]\n",
        "    print(f\"\\nâœ… Using: {SPEAKER_WAV}\")\n",
        "    display(Audio(SPEAKER_WAV))\n",
        "else:\n",
        "    print(\"No file uploaded. Using previous sample voice.\")"
      ],
      "metadata": {
        "id": "upload_voice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Load Model & Clone Voice { display-mode: \"form\" }\n",
        "import torch\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "print(\"Loading viXTTS model...\")\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(str(MODEL_DIR / \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
        "    vocab_path=str(MODEL_DIR / \"vocab.json\")\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    print(f\"âœ… Model loaded on GPU: {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    print(\"âš ï¸ Running on CPU (will be slow)\")\n",
        "\n",
        "# Clone voice\n",
        "print(f\"\\nğŸ¤ Cloning voice from: {SPEAKER_WAV}\")\n",
        "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=SPEAKER_WAV)\n",
        "print(\"âœ… Voice cloned successfully!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Generate Vietnamese Audio (viXTTS) { display-mode: \"form\" }\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Nháº­p vÄƒn báº£n tiáº¿ng Viá»‡t (10+ tá»« cho cháº¥t lÆ°á»£ng tá»‘t nháº¥t):\n",
        "text_vi = \"Xin chÃ o cÃ¡c báº¡n, Ä‘Ã¢y lÃ  giá»ng nÃ³i cá»§a tÃ´i Ä‘Æ°á»£c táº¡o báº±ng trÃ­ tuá»‡ nhÃ¢n táº¡o. CÃ´ng nghá»‡ nÃ y cho phÃ©p clone giá»ng nÃ³i chá»‰ vá»›i má»™t Ä‘oáº¡n audio ngáº¯n.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "temperature = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_file = \"vixtts_output_vi.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating: {text_vi[:50]}...\\n\")\n",
        "\n",
        "out = model.inference(\n",
        "    text_vi,\n",
        "    \"vi\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temperature\n",
        ")\n",
        "\n",
        "sf.write(output_file, out[\"wav\"], 24000)\n",
        "\n",
        "print(f\"âœ… Generated: {output_file}\")\n",
        "print(\"\\nğŸ”Š Playback:\")\n",
        "display(Audio(output_file))\n",
        "\n",
        "print(\"\\nğŸ“¥ Downloading...\")\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "vixtts_generate_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Generate English Audio (viXTTS) { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Enter English text:\n",
        "text_en = \"Welcome to The Lost Chapter. This is my voice, cloned using artificial intelligence. The technology allows creating natural sounding speech from just a short audio sample.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "temp_en = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_en = \"vixtts_output_en.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating: {text_en[:50]}...\\n\")\n",
        "\n",
        "out_en = model.inference(\n",
        "    text_en,\n",
        "    \"en\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temp_en\n",
        ")\n",
        "\n",
        "sf.write(output_en, out_en[\"wav\"], 24000)\n",
        "\n",
        "print(f\"âœ… Generated: {output_en}\")\n",
        "display(Audio(output_en))\n",
        "files.download(output_en)"
      ],
      "metadata": {
        "id": "vixtts_generate_en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Batch Generate - Audiobook Chapter (viXTTS) { display-mode: \"form\" }\n",
        "import numpy as np\n",
        "\n",
        "#@markdown ### Nháº­p nhiá»u Ä‘oáº¡n vÄƒn:\n",
        "batch_text = \"\"\"ChÆ°Æ¡ng má»™t: HÃ nh trÃ¬nh báº¯t Ä‘áº§u.\n",
        "\n",
        "NgÃ y xÆ°a, á»Ÿ má»™t vÆ°Æ¡ng quá»‘c xa xÃ´i, cÃ³ má»™t chÃ ng trai tráº» tÃªn lÃ  Minh. Minh luÃ´n mÆ¡ Æ°á»›c Ä‘Æ°á»£c khÃ¡m phÃ¡ tháº¿ giá»›i rá»™ng lá»›n bÃªn ngoÃ i ngÃ´i lÃ ng nhá» cá»§a mÃ¬nh.\n",
        "\n",
        "Má»™t ngÃ y ná», khi máº·t trá»i vá»«a lÃ³ dáº¡ng, Minh quyáº¿t Ä‘á»‹nh lÃªn Ä‘Æ°á»ng. ChÃ ng mang theo má»™t chiáº¿c ba lÃ´ nhá» chá»©a Ä‘áº§y hy vá»ng vÃ  nhá»¯ng giáº¥c mÆ¡ chÆ°a thÃ nh hiá»‡n thá»±c.\n",
        "\n",
        "Con Ä‘Æ°á»ng phÃ­a trÆ°á»›c dÃ i vÃ  Ä‘áº§y thá»­ thÃ¡ch, nhÆ°ng Minh khÃ´ng há» sá»£ hÃ£i. ChÃ ng biáº¿t ráº±ng má»—i bÆ°á»›c chÃ¢n Ä‘á»u Ä‘Æ°a mÃ¬nh Ä‘áº¿n gáº§n hÆ¡n vá»›i sá»‘ pháº­n cá»§a chÃ­nh mÃ¬nh.\"\"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "batch_lang = \"vi\" #@param [\"vi\", \"en\"]\n",
        "batch_output = \"chapter_audio.wav\" #@param {type:\"string\"}\n",
        "\n",
        "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
        "print(f\"ğŸ“– Found {len(paragraphs)} paragraphs\\n\")\n",
        "\n",
        "all_audio = []\n",
        "silence = np.zeros(int(24000 * 0.7))  # 0.7s pause\n",
        "\n",
        "for i, para in enumerate(paragraphs):\n",
        "    print(f\"[{i+1}/{len(paragraphs)}] {para[:45]}...\")\n",
        "    out = model.inference(\n",
        "        para,\n",
        "        batch_lang,\n",
        "        gpt_cond_latent,\n",
        "        speaker_embedding,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    all_audio.append(out[\"wav\"])\n",
        "    if i < len(paragraphs) - 1:\n",
        "        all_audio.append(silence)\n",
        "\n",
        "combined = np.concatenate(all_audio)\n",
        "sf.write(batch_output, combined, 24000)\n",
        "\n",
        "duration = len(combined) / 24000\n",
        "print(f\"\\nâœ… Generated: {batch_output}\")\n",
        "print(f\"â±ï¸ Duration: {duration:.1f} seconds ({duration/60:.1f} minutes)\")\n",
        "display(Audio(batch_output))\n",
        "files.download(batch_output)"
      ],
      "metadata": {
        "id": "vixtts_batch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ğŸ“‹ Tips & Troubleshooting\n",
        "\n",
        "### Vietnamese Quality (viXTTS)\n",
        "- Use sentences with **10+ words** for best results\n",
        "- Shorter sentences may produce odd trailing sounds\n",
        "- Temperature 0.6-0.8 works best\n",
        "\n",
        "### Voice Sample Requirements\n",
        "- **6-30 seconds** of clear speech\n",
        "- No background noise/music\n",
        "- Natural speaking pace\n",
        "- WAV format preferred\n",
        "\n",
        "### Temperature Settings\n",
        "| Value | Result |\n",
        "|-------|--------|\n",
        "| 0.3-0.5 | Very consistent, robotic |\n",
        "| 0.6-0.7 | Natural, stable |\n",
        "| 0.8-0.9 | Expressive, varied |\n",
        "| 1.0+ | Unstable, experimental |\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "**\"No GPU available\"**\n",
        "â†’ Go to Runtime > Change runtime type > T4 GPU\n",
        "\n",
        "**\"CUDA out of memory\"**\n",
        "â†’ Runtime > Restart runtime, then run again\n",
        "\n",
        "**Audio sounds robotic**\n",
        "â†’ Increase temperature to 0.8\n",
        "â†’ Use longer sentences\n",
        "\n",
        "**Edge TTS not working**\n",
        "â†’ Try different voice option\n",
        "â†’ Check internet connection\n",
        "\n",
        "### Supported Languages (viXTTS)\n",
        "ğŸ‡»ğŸ‡³ Vietnamese, ğŸ‡ºğŸ‡¸ English, ğŸ‡ªğŸ‡¸ Spanish, ğŸ‡«ğŸ‡· French, ğŸ‡©ğŸ‡ª German, ğŸ‡®ğŸ‡¹ Italian, ğŸ‡µğŸ‡¹ Portuguese, ğŸ‡µğŸ‡± Polish, ğŸ‡¹ğŸ‡· Turkish, ğŸ‡·ğŸ‡º Russian, ğŸ‡³ğŸ‡± Dutch, ğŸ‡¨ğŸ‡¿ Czech, ğŸ‡¸ğŸ‡¦ Arabic, ğŸ‡¨ğŸ‡³ Chinese, ğŸ‡¯ğŸ‡µ Japanese, ğŸ‡­ğŸ‡º Hungarian, ğŸ‡°ğŸ‡· Korean, ğŸ‡®ğŸ‡³ Hindi\n",
        "\n",
        "---\n",
        "\n",
        "**TheLostChapter** | [GitHub](https://github.com/nmnhut-it/english-learning-app/tree/main/the-lost-chapter) | [viXTTS Demo](https://huggingface.co/spaces/thinhlpg/vixtts-demo)"
      ],
      "metadata": {
        "id": "tips"
      }
    }
  ]
}
