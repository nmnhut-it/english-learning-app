{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üéß TheLostChapter - TTS Voice Cloning\n",
        "\n",
        "Generate audiobook narration in **Vietnamese** and **English**.\n",
        "\n",
        "## 2 Options:\n",
        "\n",
        "| Method | Voice Clone | Quality | Speed | GPU |\n",
        "|--------|-------------|---------|-------|-----|\n",
        "| **Edge TTS** | ‚ùå No | Good | Fast | Not needed |\n",
        "| **viXTTS** | ‚úÖ Yes | Best | Slower | Recommended |\n",
        "\n",
        "## Quick Start\n",
        "- **Just want Vietnamese TTS?** ‚Üí Skip to **Section A: Edge TTS** (no setup needed)\n",
        "- **Want to clone your voice?** ‚Üí Go to **Section B: viXTTS**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üÖ∞Ô∏è Section A: Edge TTS (Easy - No Voice Cloning)\n",
        "\n",
        "Microsoft's neural voices. High quality, fast, no GPU needed.\n",
        "\n",
        "**Available Vietnamese voices:**\n",
        "- `vi-VN-HoaiMyNeural` - N·ªØ (Female)\n",
        "- `vi-VN-NamMinhNeural` - Nam (Male)"
      ],
      "metadata": {
        "id": "edge_section"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edge_install"
      },
      "outputs": [],
      "source": [
        "#@title 1. Install Edge TTS { display-mode: \"form\" }\n",
        "!pip install -q edge-tts\n",
        "print(\"‚úÖ Edge TTS installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Generate Vietnamese Audio (Edge TTS) { display-mode: \"form\" }\n",
        "import edge_tts\n",
        "import asyncio\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát:\n",
        "text = \"Xin ch√†o c√°c b·∫°n, ƒë√¢y l√† gi·ªçng ƒë·ªçc t·ª´ Microsoft Edge. Ch·∫•t l∆∞·ª£ng kh√° t·ªët v√† ho√†n to√†n mi·ªÖn ph√≠, kh√¥ng c·∫ßn GPU hay voice sample.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Ch·ªçn gi·ªçng ƒë·ªçc:\n",
        "voice = \"vi-VN-HoaiMyNeural\" #@param [\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\"]\n",
        "\n",
        "#@markdown ### T√™n file output:\n",
        "output_file = \"output_vi.mp3\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating with voice: {voice}\")\n",
        "print(f\"Text: {text[:60]}...\\n\")\n",
        "\n",
        "async def generate():\n",
        "    communicate = edge_tts.Communicate(text, voice)\n",
        "    await communicate.save(output_file)\n",
        "\n",
        "await generate()\n",
        "\n",
        "print(f\"‚úÖ Generated: {output_file}\")\n",
        "print(\"\\nüîä Playback:\")\n",
        "display(Audio(output_file))\n",
        "\n",
        "print(\"\\nüì• Downloading...\")\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "edge_generate_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Generate English Audio (Edge TTS) { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Enter English text:\n",
        "text_en = \"Welcome to The Lost Chapter, an interactive audiobook experience. This voice is generated using Microsoft Edge neural text to speech.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Select voice:\n",
        "voice_en = \"en-US-GuyNeural\" #@param [\"en-US-GuyNeural\", \"en-US-JennyNeural\", \"en-GB-RyanNeural\", \"en-GB-SoniaNeural\", \"en-AU-WilliamNeural\"]\n",
        "\n",
        "output_en = \"output_en.mp3\" #@param {type:\"string\"}\n",
        "\n",
        "async def generate_en():\n",
        "    communicate = edge_tts.Communicate(text_en, voice_en)\n",
        "    await communicate.save(output_en)\n",
        "\n",
        "await generate_en()\n",
        "\n",
        "print(f\"‚úÖ Generated: {output_en}\")\n",
        "display(Audio(output_en))\n",
        "files.download(output_en)"
      ],
      "metadata": {
        "id": "edge_generate_en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Batch Generate - Multiple Paragraphs (Edge TTS) { display-mode: \"form\" }\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "!pip install -q pydub\n",
        "\n",
        "#@markdown ### Nh·∫≠p nhi·ªÅu ƒëo·∫°n vƒÉn (c√°ch nhau b·∫±ng d√≤ng tr·ªëng):\n",
        "batch_text = \"\"\"Ch∆∞∆°ng m·ªôt: Kh·ªüi ƒë·∫ßu.\n",
        "\n",
        "Ng√†y x∆∞a, ·ªü m·ªôt v∆∞∆°ng qu·ªëc xa x√¥i, c√≥ m·ªôt ch√†ng trai tr·∫ª t√™n l√† Minh. Minh lu√¥n m∆° ∆∞·ªõc ƒë∆∞·ª£c kh√°m ph√° th·∫ø gi·ªõi r·ªông l·ªõn ngo√†i kia.\n",
        "\n",
        "M·ªôt ng√†y n·ªç, Minh quy·∫øt ƒë·ªãnh r·ªùi kh·ªèi ng√¥i l√†ng nh·ªè c·ªßa m√¨nh ƒë·ªÉ b·∫Øt ƒë·∫ßu cu·ªôc phi√™u l∆∞u m·ªõi. Ch√†ng mang theo m·ªôt chi·∫øc ba l√¥ nh·ªè v√† tr√°i tim ƒë·∫ßy hy v·ªçng.\"\"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "batch_voice = \"vi-VN-HoaiMyNeural\" #@param [\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\", \"en-US-GuyNeural\", \"en-US-JennyNeural\"]\n",
        "batch_output = \"batch_output.mp3\" #@param {type:\"string\"}\n",
        "pause_ms = 800 #@param {type:\"integer\"}\n",
        "\n",
        "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
        "print(f\"Found {len(paragraphs)} paragraphs\\n\")\n",
        "\n",
        "os.makedirs('temp_audio', exist_ok=True)\n",
        "audio_segments = []\n",
        "\n",
        "for i, para in enumerate(paragraphs):\n",
        "    print(f\"[{i+1}/{len(paragraphs)}] {para[:50]}...\")\n",
        "    temp_file = f\"temp_audio/para_{i}.mp3\"\n",
        "\n",
        "    async def gen(p, f):\n",
        "        comm = edge_tts.Communicate(p, batch_voice)\n",
        "        await comm.save(f)\n",
        "\n",
        "    await gen(para, temp_file)\n",
        "    audio_segments.append(AudioSegment.from_mp3(temp_file))\n",
        "\n",
        "# Combine with pauses\n",
        "silence = AudioSegment.silent(duration=pause_ms)\n",
        "combined = audio_segments[0]\n",
        "for seg in audio_segments[1:]:\n",
        "    combined += silence + seg\n",
        "\n",
        "combined.export(batch_output, format=\"mp3\")\n",
        "\n",
        "print(f\"\\n‚úÖ Combined: {batch_output}\")\n",
        "print(f\"Duration: {len(combined)/1000:.1f} seconds\")\n",
        "display(Audio(batch_output))\n",
        "files.download(batch_output)\n",
        "\n",
        "# Cleanup\n",
        "!rm -rf temp_audio"
      ],
      "metadata": {
        "id": "edge_batch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üÖ±Ô∏è Section B: viXTTS (Voice Cloning)\n",
        "\n",
        "Clone your voice or use sample voices. Better quality but requires GPU.\n",
        "\n",
        "**‚ö†Ô∏è Requirements:**\n",
        "- Runtime > Change runtime type > **T4 GPU**\n",
        "- ~2GB download for model"
      ],
      "metadata": {
        "id": "vixtts_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Install viXTTS Dependencies { display-mode: \"form\" }\n",
        "import sys\n",
        "\n",
        "# Check Python version\n",
        "py_version = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n",
        "print(f\"Python version: {py_version}\")\n",
        "\n",
        "# Install compatible TTS version\n",
        "if sys.version_info.minor >= 12:\n",
        "    print(\"Python 3.12+ detected, using latest TTS...\")\n",
        "    !pip install -q TTS\n",
        "else:\n",
        "    print(\"Installing TTS 0.22.0...\")\n",
        "    !pip install -q TTS==0.22.0\n",
        "\n",
        "!pip install -q soundfile huggingface_hub edge-tts pydub\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed!\")"
      ],
      "metadata": {
        "id": "vixtts_install"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Download viXTTS Model (~2GB) { display-mode: \"form\" }\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pathlib import Path\n",
        "\n",
        "MODEL_DIR = Path(\"/content/models/vixtts\")\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_files = [\"config.json\", \"model.pth\", \"vocab.json\"]\n",
        "\n",
        "print(\"Downloading viXTTS model from capleaf/viXTTS...\")\n",
        "for filename in model_files:\n",
        "    target = MODEL_DIR / filename\n",
        "    if not target.exists():\n",
        "        print(f\"  üì• {filename}...\")\n",
        "        hf_hub_download(\n",
        "            repo_id=\"capleaf/viXTTS\",\n",
        "            filename=filename,\n",
        "            local_dir=str(MODEL_DIR),\n",
        "            local_dir_use_symlinks=False\n",
        "        )\n",
        "    else:\n",
        "        print(f\"  ‚úì {filename} (cached)\")\n",
        "\n",
        "print(\"\\n‚úÖ viXTTS model ready!\")"
      ],
      "metadata": {
        "id": "vixtts_download"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Create Sample Voice (using Edge TTS) { display-mode: \"form\" }\n",
        "#@markdown Generate a sample Vietnamese voice using Edge TTS.\n",
        "#@markdown This will be used as the reference voice for cloning.\n",
        "#@markdown **Skip this cell if you want to upload your own voice.**\n",
        "\n",
        "import edge_tts\n",
        "from pydub import AudioSegment\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "#@markdown ### Select voice type:\n",
        "voice_type = \"vietnamese_female\" #@param [\"vietnamese_female\", \"vietnamese_male\", \"english_female\", \"english_male\"]\n",
        "\n",
        "VOICE_MAP = {\n",
        "    \"vietnamese_female\": (\"vi-VN-HoaiMyNeural\", \"Xin ch√†o c√°c b·∫°n, t√¥i l√† m·ªôt tr·ª£ l√Ω ·∫£o th√¥ng minh. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n ƒë·ªçc s√°ch, k·ªÉ chuy·ªán, v√† nhi·ªÅu ƒëi·ªÅu th√∫ v·ªã kh√°c. H√£y c√πng kh√°m ph√° th·∫ø gi·ªõi c·ªßa nh·ªØng c√¢u chuy·ªán tuy·ªát v·ªùi nh√©.\"),\n",
        "    \"vietnamese_male\": (\"vi-VN-NamMinhNeural\", \"Xin ch√†o c√°c b·∫°n, t√¥i l√† m·ªôt tr·ª£ l√Ω ·∫£o th√¥ng minh. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n ƒë·ªçc s√°ch, k·ªÉ chuy·ªán, v√† nhi·ªÅu ƒëi·ªÅu th√∫ v·ªã kh√°c. H√£y c√πng kh√°m ph√° th·∫ø gi·ªõi c·ªßa nh·ªØng c√¢u chuy·ªán tuy·ªát v·ªùi nh√©.\"),\n",
        "    \"english_female\": (\"en-US-JennyNeural\", \"Hello everyone, I am an intelligent virtual assistant. I can help you read books, tell stories, and many other interesting things. Let us explore the world of wonderful stories together.\"),\n",
        "    \"english_male\": (\"en-US-GuyNeural\", \"Hello everyone, I am an intelligent virtual assistant. I can help you read books, tell stories, and many other interesting things. Let us explore the world of wonderful stories together.\"),\n",
        "}\n",
        "\n",
        "Path(\"samples\").mkdir(exist_ok=True)\n",
        "edge_voice, sample_text = VOICE_MAP[voice_type]\n",
        "\n",
        "# Generate with Edge TTS (MP3) then convert to WAV\n",
        "temp_mp3 = f\"samples/{voice_type}_temp.mp3\"\n",
        "SPEAKER_WAV = f\"samples/{voice_type}.wav\"\n",
        "\n",
        "print(f\"Generating {voice_type} sample with Edge TTS...\")\n",
        "\n",
        "async def create_sample():\n",
        "    communicate = edge_tts.Communicate(sample_text, edge_voice)\n",
        "    await communicate.save(temp_mp3)\n",
        "\n",
        "await create_sample()\n",
        "\n",
        "# Convert MP3 to WAV (required by viXTTS)\n",
        "audio = AudioSegment.from_mp3(temp_mp3)\n",
        "audio = audio.set_frame_rate(22050).set_channels(1)  # Mono, 22kHz\n",
        "audio.export(SPEAKER_WAV, format=\"wav\")\n",
        "\n",
        "# Clean up temp file\n",
        "import os\n",
        "os.remove(temp_mp3)\n",
        "\n",
        "print(f\"‚úÖ Created sample voice: {SPEAKER_WAV}\")\n",
        "print(f\"Duration: {len(audio)/1000:.1f} seconds\")\n",
        "print(\"\\nüîä Preview:\")\n",
        "display(Audio(SPEAKER_WAV))"
      ],
      "metadata": {
        "id": "create_sample_voice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. OR Upload Your Own Voice Sample { display-mode: \"form\" }\n",
        "#@markdown Upload 6-30 seconds of clear speech (WAV/MP3).\n",
        "#@markdown **Skip this if you used the sample voice above.**\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "print(\"Select your voice sample file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    SPEAKER_WAV = list(uploaded.keys())[0]\n",
        "    print(f\"\\n‚úÖ Using: {SPEAKER_WAV}\")\n",
        "    display(Audio(SPEAKER_WAV))\n",
        "else:\n",
        "    print(\"No file uploaded. Using previous sample voice.\")"
      ],
      "metadata": {
        "id": "upload_voice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Load Model & Clone Voice { display-mode: \"form\" }\n",
        "import torch\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "\n",
        "print(\"Loading viXTTS model...\")\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(str(MODEL_DIR / \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
        "    vocab_path=str(MODEL_DIR / \"vocab.json\")\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    print(f\"‚úÖ Model loaded on GPU: {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Running on CPU (will be slow)\")\n",
        "\n",
        "# Clone voice\n",
        "print(f\"\\nüé§ Cloning voice from: {SPEAKER_WAV}\")\n",
        "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=SPEAKER_WAV)\n",
        "print(\"‚úÖ Voice cloned successfully!\")"
      ],
      "metadata": {
        "id": "load_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Generate Vietnamese Audio (viXTTS) { display-mode: \"form\" }\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát (10+ t·ª´ cho ch·∫•t l∆∞·ª£ng t·ªët nh·∫•t):\n",
        "text_vi = \"Xin ch√†o c√°c b·∫°n, ƒë√¢y l√† gi·ªçng n√≥i c·ªßa t√¥i ƒë∆∞·ª£c t·∫°o b·∫±ng tr√≠ tu·ªá nh√¢n t·∫°o. C√¥ng ngh·ªá n√†y cho ph√©p clone gi·ªçng n√≥i ch·ªâ v·ªõi m·ªôt ƒëo·∫°n audio ng·∫Øn.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "temperature = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_file = \"vixtts_output_vi.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating: {text_vi[:50]}...\\n\")\n",
        "\n",
        "out = model.inference(\n",
        "    text_vi,\n",
        "    \"vi\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temperature\n",
        ")\n",
        "\n",
        "sf.write(output_file, out[\"wav\"], 24000)\n",
        "\n",
        "print(f\"‚úÖ Generated: {output_file}\")\n",
        "print(\"\\nüîä Playback:\")\n",
        "display(Audio(output_file))\n",
        "\n",
        "print(\"\\nüì• Downloading...\")\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "id": "vixtts_generate_vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Generate English Audio (viXTTS) { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Enter English text:\n",
        "text_en = \"Welcome to The Lost Chapter. This is my voice, cloned using artificial intelligence. The technology allows creating natural sounding speech from just a short audio sample.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "temp_en = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_en = \"vixtts_output_en.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"Generating: {text_en[:50]}...\\n\")\n",
        "\n",
        "out_en = model.inference(\n",
        "    text_en,\n",
        "    \"en\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temp_en\n",
        ")\n",
        "\n",
        "sf.write(output_en, out_en[\"wav\"], 24000)\n",
        "\n",
        "print(f\"‚úÖ Generated: {output_en}\")\n",
        "display(Audio(output_en))\n",
        "files.download(output_en)"
      ],
      "metadata": {
        "id": "vixtts_generate_en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. Batch Generate - Audiobook Chapter (viXTTS) { display-mode: \"form\" }\n",
        "import numpy as np\n",
        "\n",
        "#@markdown ### Nh·∫≠p nhi·ªÅu ƒëo·∫°n vƒÉn:\n",
        "batch_text = \"\"\"Ch∆∞∆°ng m·ªôt: H√†nh tr√¨nh b·∫Øt ƒë·∫ßu.\n",
        "\n",
        "Ng√†y x∆∞a, ·ªü m·ªôt v∆∞∆°ng qu·ªëc xa x√¥i, c√≥ m·ªôt ch√†ng trai tr·∫ª t√™n l√† Minh. Minh lu√¥n m∆° ∆∞·ªõc ƒë∆∞·ª£c kh√°m ph√° th·∫ø gi·ªõi r·ªông l·ªõn b√™n ngo√†i ng√¥i l√†ng nh·ªè c·ªßa m√¨nh.\n",
        "\n",
        "M·ªôt ng√†y n·ªç, khi m·∫∑t tr·ªùi v·ª´a l√≥ d·∫°ng, Minh quy·∫øt ƒë·ªãnh l√™n ƒë∆∞·ªùng. Ch√†ng mang theo m·ªôt chi·∫øc ba l√¥ nh·ªè ch·ª©a ƒë·∫ßy hy v·ªçng v√† nh·ªØng gi·∫•c m∆° ch∆∞a th√†nh hi·ªán th·ª±c.\n",
        "\n",
        "Con ƒë∆∞·ªùng ph√≠a tr∆∞·ªõc d√†i v√† ƒë·∫ßy th·ª≠ th√°ch, nh∆∞ng Minh kh√¥ng h·ªÅ s·ª£ h√£i. Ch√†ng bi·∫øt r·∫±ng m·ªói b∆∞·ªõc ch√¢n ƒë·ªÅu ƒë∆∞a m√¨nh ƒë·∫øn g·∫ßn h∆°n v·ªõi s·ªë ph·∫≠n c·ªßa ch√≠nh m√¨nh.\"\"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "batch_lang = \"vi\" #@param [\"vi\", \"en\"]\n",
        "batch_output = \"chapter_audio.wav\" #@param {type:\"string\"}\n",
        "\n",
        "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
        "print(f\"üìñ Found {len(paragraphs)} paragraphs\\n\")\n",
        "\n",
        "all_audio = []\n",
        "silence = np.zeros(int(24000 * 0.7))  # 0.7s pause\n",
        "\n",
        "for i, para in enumerate(paragraphs):\n",
        "    print(f\"[{i+1}/{len(paragraphs)}] {para[:45]}...\")\n",
        "    out = model.inference(\n",
        "        para,\n",
        "        batch_lang,\n",
        "        gpt_cond_latent,\n",
        "        speaker_embedding,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    all_audio.append(out[\"wav\"])\n",
        "    if i < len(paragraphs) - 1:\n",
        "        all_audio.append(silence)\n",
        "\n",
        "combined = np.concatenate(all_audio)\n",
        "sf.write(batch_output, combined, 24000)\n",
        "\n",
        "duration = len(combined) / 24000\n",
        "print(f\"\\n‚úÖ Generated: {batch_output}\")\n",
        "print(f\"‚è±Ô∏è Duration: {duration:.1f} seconds ({duration/60:.1f} minutes)\")\n",
        "display(Audio(batch_output))\n",
        "files.download(batch_output)"
      ],
      "metadata": {
        "id": "vixtts_batch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìã Tips & Troubleshooting\n",
        "\n",
        "### Vietnamese Quality (viXTTS)\n",
        "- Use sentences with **10+ words** for best results\n",
        "- Shorter sentences may produce odd trailing sounds\n",
        "- Temperature 0.6-0.8 works best\n",
        "\n",
        "### Voice Sample Requirements\n",
        "- **6-30 seconds** of clear speech\n",
        "- No background noise/music\n",
        "- Natural speaking pace\n",
        "- WAV format preferred\n",
        "\n",
        "### Temperature Settings\n",
        "| Value | Result |\n",
        "|-------|--------|\n",
        "| 0.3-0.5 | Very consistent, robotic |\n",
        "| 0.6-0.7 | Natural, stable |\n",
        "| 0.8-0.9 | Expressive, varied |\n",
        "| 1.0+ | Unstable, experimental |\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "**\"No GPU available\"**\n",
        "‚Üí Go to Runtime > Change runtime type > T4 GPU\n",
        "\n",
        "**\"CUDA out of memory\"**\n",
        "‚Üí Runtime > Restart runtime, then run again\n",
        "\n",
        "**Audio sounds robotic**\n",
        "‚Üí Increase temperature to 0.8\n",
        "‚Üí Use longer sentences\n",
        "\n",
        "**Edge TTS not working**\n",
        "‚Üí Try different voice option\n",
        "‚Üí Check internet connection\n",
        "\n",
        "### Supported Languages (viXTTS)\n",
        "üáªüá≥ Vietnamese, üá∫üá∏ English, üá™üá∏ Spanish, üá´üá∑ French, üá©üá™ German, üáÆüáπ Italian, üáµüáπ Portuguese, üáµüá± Polish, üáπüá∑ Turkish, üá∑üá∫ Russian, üá≥üá± Dutch, üá®üáø Czech, üá∏üá¶ Arabic, üá®üá≥ Chinese, üáØüáµ Japanese, üá≠üá∫ Hungarian, üá∞üá∑ Korean, üáÆüá≥ Hindi\n",
        "\n",
        "---\n",
        "\n",
        "**TheLostChapter** | [GitHub](https://github.com/nmnhut-it/english-learning-app/tree/main/the-lost-chapter) | [viXTTS Demo](https://huggingface.co/spaces/thinhlpg/vixtts-demo)"
      ],
      "metadata": {
        "id": "tips"
      }
    }
  ]
}
