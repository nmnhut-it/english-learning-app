{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéß TheLostChapter - Vietnamese Voice Cloning\n",
        "\n",
        "Generate audiobook narration with **your cloned voice** in Vietnamese and English.\n",
        "\n",
        "**Model:** [viXTTS](https://huggingface.co/capleaf/viXTTS) - Fine-tuned XTTS v2 for Vietnamese\n",
        "\n",
        "## ‚ö†Ô∏è Requirements\n",
        "1. Go to **Runtime ‚Üí Change runtime type ‚Üí T4 GPU**\n",
        "2. Run cells 1-4 in order\n",
        "3. Then use cells 5-7 to generate audio\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title 1. Install Dependencies { display-mode: \"form\" }\n",
        "#@markdown Installs coqui-tts (Python 3.12+ compatible) and audio libraries\n",
        "\n",
        "import sys\n",
        "print(f\"Python version: {sys.version_info.major}.{sys.version_info.minor}\")\n",
        "\n",
        "# Install coqui-tts fork (supports Python 3.12+)\n",
        "print(\"\\nüì¶ Installing coqui-tts...\")\n",
        "!pip install -q coqui-tts\n",
        "\n",
        "# Install audio dependencies\n",
        "print(\"üì¶ Installing audio libraries...\")\n",
        "!pip install -q torchcodec soundfile huggingface_hub pydub\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title 2. Download viXTTS Model (~2GB) { display-mode: \"form\" }\n",
        "from huggingface_hub import hf_hub_download\n",
        "from pathlib import Path\n",
        "\n",
        "MODEL_DIR = Path(\"/content/models/vixtts\")\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model_files = [\"config.json\", \"model.pth\", \"vocab.json\"]\n",
        "\n",
        "print(\"üì• Downloading viXTTS model from capleaf/viXTTS...\\n\")\n",
        "for filename in model_files:\n",
        "    target = MODEL_DIR / filename\n",
        "    if not target.exists():\n",
        "        print(f\"  Downloading {filename}...\")\n",
        "        hf_hub_download(\n",
        "            repo_id=\"capleaf/viXTTS\",\n",
        "            filename=filename,\n",
        "            local_dir=str(MODEL_DIR),\n",
        "            local_dir_use_symlinks=False\n",
        "        )\n",
        "    else:\n",
        "        print(f\"  ‚úì {filename} (cached)\")\n",
        "\n",
        "print(\"\\n‚úÖ viXTTS model ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title 3. Upload Your Voice Sample { display-mode: \"form\" }\n",
        "#@markdown Upload **6-30 seconds** of clear speech (WAV or MP3).\n",
        "#@markdown - No background noise or music\n",
        "#@markdown - Natural speaking pace\n",
        "#@markdown - Single speaker only\n",
        "\n",
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import Audio, display\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "Path(\"samples\").mkdir(exist_ok=True)\n",
        "\n",
        "print(\"üìÅ Select your voice sample file (WAV/MP3):\\n\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    uploaded_file = list(uploaded.keys())[0]\n",
        "    \n",
        "    # Convert to WAV if needed\n",
        "    if uploaded_file.endswith('.mp3'):\n",
        "        print(\"\\nüîÑ Converting MP3 to WAV...\")\n",
        "        audio = AudioSegment.from_mp3(uploaded_file)\n",
        "        SPEAKER_WAV = \"samples/speaker.wav\"\n",
        "        audio = audio.set_frame_rate(22050).set_channels(1)\n",
        "        audio.export(SPEAKER_WAV, format=\"wav\")\n",
        "        os.remove(uploaded_file)\n",
        "    else:\n",
        "        SPEAKER_WAV = f\"samples/{uploaded_file}\"\n",
        "        os.rename(uploaded_file, SPEAKER_WAV)\n",
        "    \n",
        "    # Get duration\n",
        "    audio = AudioSegment.from_wav(SPEAKER_WAV)\n",
        "    duration = len(audio) / 1000\n",
        "    \n",
        "    print(f\"\\n‚úÖ Voice sample ready: {SPEAKER_WAV}\")\n",
        "    print(f\"‚è±Ô∏è Duration: {duration:.1f} seconds\")\n",
        "    \n",
        "    if duration < 6:\n",
        "        print(\"\\n‚ö†Ô∏è Warning: Sample is short. 6-30 seconds recommended for best quality.\")\n",
        "    elif duration > 30:\n",
        "        print(\"\\n‚ö†Ô∏è Warning: Sample is long. This may slow down processing.\")\n",
        "    \n",
        "    print(\"\\nüîä Preview:\")\n",
        "    display(Audio(SPEAKER_WAV))\n",
        "else:\n",
        "    print(\"‚ùå No file uploaded. Please run this cell again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title 4. Load Model & Clone Voice { display-mode: \"form\" }\n",
        "import torch\n",
        "import re\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.tts.layers.xtts import tokenizer as xtts_tokenizer\n",
        "\n",
        "# Patch tokenizer to support Vietnamese\n",
        "print(\"üîß Patching tokenizer for Vietnamese...\")\n",
        "\n",
        "_original_preprocess = xtts_tokenizer.VoiceBpeTokenizer.preprocess_text\n",
        "\n",
        "def _patched_preprocess(self, txt, lang):\n",
        "    \"\"\"Patched to support Vietnamese language.\"\"\"\n",
        "    if lang == \"vi\":\n",
        "        # Simple text cleaning for Vietnamese (Latin script)\n",
        "        txt = txt.replace('\"', '')\n",
        "        txt = re.sub(r'\\s+', ' ', txt)\n",
        "        txt = txt.strip()\n",
        "        return txt\n",
        "    return _original_preprocess(self, txt, lang)\n",
        "\n",
        "xtts_tokenizer.VoiceBpeTokenizer.preprocess_text = _patched_preprocess\n",
        "print(\"‚úÖ Vietnamese support enabled\")\n",
        "\n",
        "# Load model\n",
        "print(\"\\nüöÄ Loading viXTTS model...\")\n",
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(str(MODEL_DIR / \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
        "    vocab_path=str(MODEL_DIR / \"vocab.json\")\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    print(f\"‚úÖ Model loaded on GPU: {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Running on CPU (will be slow). Enable GPU in Runtime settings.\")\n",
        "\n",
        "# Clone voice\n",
        "print(f\"\\nüé§ Cloning voice from: {SPEAKER_WAV}\")\n",
        "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=SPEAKER_WAV)\n",
        "print(\"\\n‚úÖ Voice cloned successfully! Ready to generate audio.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üéôÔ∏è Generate Audio\n",
        "\n",
        "Now you can generate audio with your cloned voice!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title 5. Generate Vietnamese Audio { display-mode: \"form\" }\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio, display\n",
        "from google.colab import files\n",
        "\n",
        "#@markdown ### Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát:\n",
        "text_vi = \"Xin ch√†o c√°c b·∫°n, ƒë√¢y l√† gi·ªçng n√≥i c·ªßa t√¥i ƒë∆∞·ª£c t·∫°o b·∫±ng tr√≠ tu·ªá nh√¢n t·∫°o. C√¥ng ngh·ªá n√†y cho ph√©p clone gi·ªçng n√≥i ch·ªâ v·ªõi m·ªôt ƒëo·∫°n audio ng·∫Øn.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### C√†i ƒë·∫∑t:\n",
        "temperature = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_file = \"output_vi.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"üìù Text: {text_vi[:60]}...\\n\")\n",
        "print(\"‚è≥ Generating...\")\n",
        "\n",
        "out = model.inference(\n",
        "    text_vi,\n",
        "    \"vi\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temperature\n",
        ")\n",
        "\n",
        "sf.write(output_file, out[\"wav\"], 24000)\n",
        "\n",
        "duration = len(out[\"wav\"]) / 24000\n",
        "print(f\"\\n‚úÖ Generated: {output_file} ({duration:.1f}s)\")\n",
        "print(\"\\nüîä Playback:\")\n",
        "display(Audio(output_file))\n",
        "\n",
        "print(\"\\nüì• Downloading...\")\n",
        "files.download(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title 6. Generate English Audio { display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Enter English text:\n",
        "text_en = \"Welcome to The Lost Chapter. This is my voice, cloned using artificial intelligence. The technology allows creating natural sounding speech from just a short audio sample.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Settings:\n",
        "temperature_en = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "output_en = \"output_en.wav\" #@param {type:\"string\"}\n",
        "\n",
        "print(f\"üìù Text: {text_en[:60]}...\\n\")\n",
        "print(\"‚è≥ Generating...\")\n",
        "\n",
        "out_en = model.inference(\n",
        "    text_en,\n",
        "    \"en\",\n",
        "    gpt_cond_latent,\n",
        "    speaker_embedding,\n",
        "    temperature=temperature_en\n",
        ")\n",
        "\n",
        "sf.write(output_en, out_en[\"wav\"], 24000)\n",
        "\n",
        "duration = len(out_en[\"wav\"]) / 24000\n",
        "print(f\"\\n‚úÖ Generated: {output_en} ({duration:.1f}s)\")\n",
        "print(\"\\nüîä Playback:\")\n",
        "display(Audio(output_en))\n",
        "\n",
        "print(\"\\nüì• Downloading...\")\n",
        "files.download(output_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#@title 7. Batch Generate - Audiobook Chapter { display-mode: \"form\" }\n",
        "import numpy as np\n",
        "\n",
        "#@markdown ### Nh·∫≠p nhi·ªÅu ƒëo·∫°n vƒÉn (c√°ch nhau b·∫±ng d√≤ng tr·ªëng):\n",
        "batch_text = \"\"\"Ch∆∞∆°ng m·ªôt: H√†nh tr√¨nh b·∫Øt ƒë·∫ßu.\n",
        "\n",
        "Ng√†y x∆∞a, ·ªü m·ªôt v∆∞∆°ng qu·ªëc xa x√¥i, c√≥ m·ªôt ch√†ng trai tr·∫ª t√™n l√† Minh. Minh lu√¥n m∆° ∆∞·ªõc ƒë∆∞·ª£c kh√°m ph√° th·∫ø gi·ªõi r·ªông l·ªõn b√™n ngo√†i ng√¥i l√†ng nh·ªè c·ªßa m√¨nh.\n",
        "\n",
        "M·ªôt ng√†y n·ªç, khi m·∫∑t tr·ªùi v·ª´a l√≥ d·∫°ng, Minh quy·∫øt ƒë·ªãnh l√™n ƒë∆∞·ªùng. Ch√†ng mang theo m·ªôt chi·∫øc ba l√¥ nh·ªè ch·ª©a ƒë·∫ßy hy v·ªçng v√† nh·ªØng gi·∫•c m∆° ch∆∞a th√†nh hi·ªán th·ª±c.\n",
        "\n",
        "Con ƒë∆∞·ªùng ph√≠a tr∆∞·ªõc d√†i v√† ƒë·∫ßy th·ª≠ th√°ch, nh∆∞ng Minh kh√¥ng h·ªÅ s·ª£ h√£i. Ch√†ng bi·∫øt r·∫±ng m·ªói b∆∞·ªõc ch√¢n ƒë·ªÅu ƒë∆∞a m√¨nh ƒë·∫øn g·∫ßn h∆°n v·ªõi s·ªë ph·∫≠n c·ªßa ch√≠nh m√¨nh.\"\"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### C√†i ƒë·∫∑t:\n",
        "batch_lang = \"vi\" #@param [\"vi\", \"en\"]\n",
        "batch_output = \"chapter_audio.wav\" #@param {type:\"string\"}\n",
        "pause_seconds = 0.7 #@param {type:\"slider\", min:0.3, max:2.0, step:0.1}\n",
        "\n",
        "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
        "print(f\"üìñ Found {len(paragraphs)} paragraphs\\n\")\n",
        "\n",
        "all_audio = []\n",
        "silence = np.zeros(int(24000 * pause_seconds))\n",
        "\n",
        "for i, para in enumerate(paragraphs):\n",
        "    print(f\"[{i+1}/{len(paragraphs)}] {para[:50]}...\")\n",
        "    out = model.inference(\n",
        "        para,\n",
        "        batch_lang,\n",
        "        gpt_cond_latent,\n",
        "        speaker_embedding,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    all_audio.append(out[\"wav\"])\n",
        "    if i < len(paragraphs) - 1:\n",
        "        all_audio.append(silence)\n",
        "\n",
        "combined = np.concatenate(all_audio)\n",
        "sf.write(batch_output, combined, 24000)\n",
        "\n",
        "duration = len(combined) / 24000\n",
        "print(f\"\\n‚úÖ Generated: {batch_output}\")\n",
        "print(f\"‚è±Ô∏è Duration: {duration:.1f}s ({duration/60:.1f} minutes)\")\n",
        "print(\"\\nüîä Playback:\")\n",
        "display(Audio(batch_output))\n",
        "\n",
        "print(\"\\nüì• Downloading...\")\n",
        "files.download(batch_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìã Tips\n",
        "\n",
        "### Best Practices\n",
        "- Use sentences with **10+ words** for natural results\n",
        "- Temperature **0.6-0.8** works best for most cases\n",
        "- Longer voice samples (15-30s) produce better cloning\n",
        "\n",
        "### Temperature Guide\n",
        "| Value | Result |\n",
        "|-------|--------|\n",
        "| 0.3-0.5 | Consistent, slightly robotic |\n",
        "| 0.6-0.7 | Natural, stable (recommended) |\n",
        "| 0.8-0.9 | Expressive, more variation |\n",
        "\n",
        "### Troubleshooting\n",
        "\n",
        "| Issue | Solution |\n",
        "|-------|----------|\n",
        "| \"No GPU available\" | Runtime ‚Üí Change runtime type ‚Üí T4 GPU |\n",
        "| \"CUDA out of memory\" | Runtime ‚Üí Restart runtime, then run again |\n",
        "| Audio sounds robotic | Increase temperature to 0.8 |\n",
        "| Odd trailing sounds | Use longer sentences (10+ words) |\n",
        "\n",
        "### Supported Languages\n",
        "üáªüá≥ Vietnamese, üá∫üá∏ English, üá™üá∏ Spanish, üá´üá∑ French, üá©üá™ German, üáÆüáπ Italian, üáµüáπ Portuguese, üáµüá± Polish, üáπüá∑ Turkish, üá∑üá∫ Russian, üá≥üá± Dutch, üá®üáø Czech, üá∏üá¶ Arabic, üá®üá≥ Chinese, üáØüáµ Japanese, üá≠üá∫ Hungarian, üá∞üá∑ Korean, üáÆüá≥ Hindi\n",
        "\n",
        "---\n",
        "\n",
        "**TheLostChapter** | [GitHub](https://github.com/nmnhut-it/english-learning-app/tree/main/the-lost-chapter) | [viXTTS Model](https://huggingface.co/capleaf/viXTTS)"
      ]
    }
  ]
}
