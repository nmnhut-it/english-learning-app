{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ğŸ§ TheLostChapter - TTS Voice Cloning\n",
    "\n",
    "Generate audiobook narration in **Vietnamese** and **English**.\n",
    "\n",
    "## 2 Options:\n",
    "\n",
    "| Method | Voice Clone | Quality | Speed | GPU |\n",
    "|--------|-------------|---------|-------|-----|\n",
    "| **Edge TTS** | âŒ No | Good | Fast | Not needed |\n",
    "| **viXTTS** | âœ… Yes | Best | Slower | Recommended |\n",
    "\n",
    "## Quick Start\n",
    "- **Just want Vietnamese TTS?** â†’ Skip to **Section A: Edge TTS** (no setup needed)\n",
    "- **Want to clone your voice?** â†’ Go to **Section B: viXTTS**\n",
    "\n",
    "---"
   ],
   "metadata": {
    "id": "header"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ğŸ…°ï¸ Section A: Edge TTS (Easy - No Voice Cloning)\n",
    "\n",
    "Microsoft's neural voices. High quality, fast, no GPU needed.\n",
    "\n",
    "**Available Vietnamese voices:**\n",
    "- `vi-VN-HoaiMyNeural` - Ná»¯ (Female)\n",
    "- `vi-VN-NamMinhNeural` - Nam (Male)"
   ],
   "metadata": {
    "id": "edge_section"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edge_install"
   },
   "outputs": [],
   "source": [
    "#@title 1. Install Edge TTS { display-mode: \"form\" }\n",
    "!pip install -q edge-tts\n",
    "print(\"âœ… Edge TTS installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 2. Generate Vietnamese Audio (Edge TTS) { display-mode: \"form\" }\n",
    "import edge_tts\n",
    "import asyncio\n",
    "from IPython.display import Audio, display\n",
    "from google.colab import files\n",
    "\n",
    "#@markdown ### Nháº­p vÄƒn báº£n tiáº¿ng Viá»‡t:\n",
    "text = \"Xin chÃ o cÃ¡c báº¡n, Ä‘Ã¢y lÃ  giá»ng Ä‘á»c tá»« Microsoft Edge. Cháº¥t lÆ°á»£ng khÃ¡ tá»‘t vÃ  hoÃ n toÃ n miá»…n phÃ­, khÃ´ng cáº§n GPU hay voice sample.\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Chá»n giá»ng Ä‘á»c:\n",
    "voice = \"vi-VN-HoaiMyNeural\" #@param [\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\"]\n",
    "\n",
    "#@markdown ### TÃªn file output:\n",
    "output_file = \"output_vi.mp3\" #@param {type:\"string\"}\n",
    "\n",
    "print(f\"Generating with voice: {voice}\")\n",
    "print(f\"Text: {text[:60]}...\\n\")\n",
    "\n",
    "async def generate():\n",
    "    communicate = edge_tts.Communicate(text, voice)\n",
    "    await communicate.save(output_file)\n",
    "\n",
    "await generate()\n",
    "\n",
    "print(f\"âœ… Generated: {output_file}\")\n",
    "print(\"\\nğŸ”Š Playback:\")\n",
    "display(Audio(output_file))\n",
    "\n",
    "print(\"\\nğŸ“¥ Downloading...\")\n",
    "files.download(output_file)"
   ],
   "metadata": {
    "id": "edge_generate_vi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 3. Generate English Audio (Edge TTS) { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ### Enter English text:\n",
    "text_en = \"Welcome to The Lost Chapter, an interactive audiobook experience. This voice is generated using Microsoft Edge neural text to speech.\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Select voice:\n",
    "voice_en = \"en-US-GuyNeural\" #@param [\"en-US-GuyNeural\", \"en-US-JennyNeural\", \"en-GB-RyanNeural\", \"en-GB-SoniaNeural\", \"en-AU-WilliamNeural\"]\n",
    "\n",
    "output_en = \"output_en.mp3\" #@param {type:\"string\"}\n",
    "\n",
    "async def generate_en():\n",
    "    communicate = edge_tts.Communicate(text_en, voice_en)\n",
    "    await communicate.save(output_en)\n",
    "\n",
    "await generate_en()\n",
    "\n",
    "print(f\"âœ… Generated: {output_en}\")\n",
    "display(Audio(output_en))\n",
    "files.download(output_en)"
   ],
   "metadata": {
    "id": "edge_generate_en"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 4. Batch Generate - Multiple Paragraphs (Edge TTS) { display-mode: \"form\" }\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "!pip install -q pydub\n",
    "\n",
    "#@markdown ### Nháº­p nhiá»u Ä‘oáº¡n vÄƒn (cÃ¡ch nhau báº±ng dÃ²ng trá»‘ng):\n",
    "batch_text = \"\"\"ChÆ°Æ¡ng má»™t: Khá»Ÿi Ä‘áº§u.\n",
    "\n",
    "NgÃ y xÆ°a, á»Ÿ má»™t vÆ°Æ¡ng quá»‘c xa xÃ´i, cÃ³ má»™t chÃ ng trai tráº» tÃªn lÃ  Minh. Minh luÃ´n mÆ¡ Æ°á»›c Ä‘Æ°á»£c khÃ¡m phÃ¡ tháº¿ giá»›i rá»™ng lá»›n ngoÃ i kia.\n",
    "\n",
    "Má»™t ngÃ y ná», Minh quyáº¿t Ä‘á»‹nh rá»i khá»i ngÃ´i lÃ ng nhá» cá»§a mÃ¬nh Ä‘á»ƒ báº¯t Ä‘áº§u cuá»™c phiÃªu lÆ°u má»›i. ChÃ ng mang theo má»™t chiáº¿c ba lÃ´ nhá» vÃ  trÃ¡i tim Ä‘áº§y hy vá»ng.\"\"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Settings:\n",
    "batch_voice = \"vi-VN-HoaiMyNeural\" #@param [\"vi-VN-HoaiMyNeural\", \"vi-VN-NamMinhNeural\", \"en-US-GuyNeural\", \"en-US-JennyNeural\"]\n",
    "batch_output = \"batch_output.mp3\" #@param {type:\"string\"}\n",
    "pause_ms = 800 #@param {type:\"integer\"}\n",
    "\n",
    "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
    "print(f\"Found {len(paragraphs)} paragraphs\\n\")\n",
    "\n",
    "os.makedirs('temp_audio', exist_ok=True)\n",
    "audio_segments = []\n",
    "\n",
    "for i, para in enumerate(paragraphs):\n",
    "    print(f\"[{i+1}/{len(paragraphs)}] {para[:50]}...\")\n",
    "    temp_file = f\"temp_audio/para_{i}.mp3\"\n",
    "\n",
    "    async def gen(p, f):\n",
    "        comm = edge_tts.Communicate(p, batch_voice)\n",
    "        await comm.save(f)\n",
    "\n",
    "    await gen(para, temp_file)\n",
    "    audio_segments.append(AudioSegment.from_mp3(temp_file))\n",
    "\n",
    "# Combine with pauses\n",
    "silence = AudioSegment.silent(duration=pause_ms)\n",
    "combined = audio_segments[0]\n",
    "for seg in audio_segments[1:]:\n",
    "    combined += silence + seg\n",
    "\n",
    "combined.export(batch_output, format=\"mp3\")\n",
    "\n",
    "print(f\"\\nâœ… Combined: {batch_output}\")\n",
    "print(f\"Duration: {len(combined)/1000:.1f} seconds\")\n",
    "display(Audio(batch_output))\n",
    "files.download(batch_output)\n",
    "\n",
    "# Cleanup\n",
    "!rm -rf temp_audio"
   ],
   "metadata": {
    "id": "edge_batch"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# ğŸ…±ï¸ Section B: viXTTS (Voice Cloning)\n",
    "\n",
    "Clone your voice or use sample voices. Better quality but requires GPU.\n",
    "\n",
    "**âš ï¸ Requirements:**\n",
    "- Runtime > Change runtime type > **T4 GPU**\n",
    "- ~2GB download for model"
   ],
   "metadata": {
    "id": "vixtts_section"
   }
  },
  {
   "cell_type": "code",
   "source": "#@title 1. Install viXTTS Dependencies { display-mode: \"form\" }\n#@markdown This uses `coqui-tts` fork which supports Python 3.12+\n\nimport sys\npy_version = f\"{sys.version_info.major}.{sys.version_info.minor}\"\nprint(f\"Python version: {py_version}\")\n\n# Install coqui-tts fork (supports Python 3.12+)\n# See: https://github.com/idiap/coqui-ai-TTS\nprint(\"Installing coqui-tts (Python 3.12+ compatible fork)...\")\n!pip install -q coqui-tts\n\n# Install torchcodec for audio loading (required by torchaudio in newer versions)\nprint(\"Installing torchcodec...\")\n!pip install -q torchcodec\n\n!pip install -q soundfile huggingface_hub edge-tts pydub\n\nprint(\"\\nâœ… Dependencies installed!\")",
   "metadata": {
    "id": "vixtts_install"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 2. Download viXTTS Model (~2GB) { display-mode: \"form\" }\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path(\"/content/models/vixtts\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_files = [\"config.json\", \"model.pth\", \"vocab.json\"]\n",
    "\n",
    "print(\"Downloading viXTTS model from capleaf/viXTTS...\")\n",
    "for filename in model_files:\n",
    "    target = MODEL_DIR / filename\n",
    "    if not target.exists():\n",
    "        print(f\"  ğŸ“¥ {filename}...\")\n",
    "        hf_hub_download(\n",
    "            repo_id=\"capleaf/viXTTS\",\n",
    "            filename=filename,\n",
    "            local_dir=str(MODEL_DIR),\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "    else:\n",
    "        print(f\"  âœ“ {filename} (cached)\")\n",
    "\n",
    "print(\"\\nâœ… viXTTS model ready!\")"
   ],
   "metadata": {
    "id": "vixtts_download"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 3. Create Sample Voice (using Edge TTS) { display-mode: \"form\" }\n",
    "#@markdown Generate a sample Vietnamese voice using Edge TTS.\n",
    "#@markdown This will be used as the reference voice for cloning.\n",
    "#@markdown **Skip this cell if you want to upload your own voice.**\n",
    "\n",
    "import edge_tts\n",
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "#@markdown ### Select voice type:\n",
    "voice_type = \"vietnamese_female\" #@param [\"vietnamese_female\", \"vietnamese_male\", \"english_female\", \"english_male\"]\n",
    "\n",
    "VOICE_MAP = {\n",
    "    \"vietnamese_female\": (\"vi-VN-HoaiMyNeural\", \"Xin chÃ o cÃ¡c báº¡n, tÃ´i lÃ  má»™t trá»£ lÃ½ áº£o thÃ´ng minh. TÃ´i cÃ³ thá»ƒ giÃºp báº¡n Ä‘á»c sÃ¡ch, ká»ƒ chuyá»‡n, vÃ  nhiá»u Ä‘iá»u thÃº vá»‹ khÃ¡c. HÃ£y cÃ¹ng khÃ¡m phÃ¡ tháº¿ giá»›i cá»§a nhá»¯ng cÃ¢u chuyá»‡n tuyá»‡t vá»i nhÃ©.\"),\n",
    "    \"vietnamese_male\": (\"vi-VN-NamMinhNeural\", \"Xin chÃ o cÃ¡c báº¡n, tÃ´i lÃ  má»™t trá»£ lÃ½ áº£o thÃ´ng minh. TÃ´i cÃ³ thá»ƒ giÃºp báº¡n Ä‘á»c sÃ¡ch, ká»ƒ chuyá»‡n, vÃ  nhiá»u Ä‘iá»u thÃº vá»‹ khÃ¡c. HÃ£y cÃ¹ng khÃ¡m phÃ¡ tháº¿ giá»›i cá»§a nhá»¯ng cÃ¢u chuyá»‡n tuyá»‡t vá»i nhÃ©.\"),\n",
    "    \"english_female\": (\"en-US-JennyNeural\", \"Hello everyone, I am an intelligent virtual assistant. I can help you read books, tell stories, and many other interesting things. Let us explore the world of wonderful stories together.\"),\n",
    "    \"english_male\": (\"en-US-GuyNeural\", \"Hello everyone, I am an intelligent virtual assistant. I can help you read books, tell stories, and many other interesting things. Let us explore the world of wonderful stories together.\"),\n",
    "}\n",
    "\n",
    "Path(\"samples\").mkdir(exist_ok=True)\n",
    "edge_voice, sample_text = VOICE_MAP[voice_type]\n",
    "\n",
    "# Generate with Edge TTS (MP3) then convert to WAV\n",
    "temp_mp3 = f\"samples/{voice_type}_temp.mp3\"\n",
    "SPEAKER_WAV = f\"samples/{voice_type}.wav\"\n",
    "\n",
    "print(f\"Generating {voice_type} sample with Edge TTS...\")\n",
    "\n",
    "async def create_sample():\n",
    "    communicate = edge_tts.Communicate(sample_text, edge_voice)\n",
    "    await communicate.save(temp_mp3)\n",
    "\n",
    "await create_sample()\n",
    "\n",
    "# Convert MP3 to WAV (required by viXTTS)\n",
    "audio = AudioSegment.from_mp3(temp_mp3)\n",
    "audio = audio.set_frame_rate(22050).set_channels(1)  # Mono, 22kHz\n",
    "audio.export(SPEAKER_WAV, format=\"wav\")\n",
    "\n",
    "# Clean up temp file\n",
    "import os\n",
    "os.remove(temp_mp3)\n",
    "\n",
    "print(f\"âœ… Created sample voice: {SPEAKER_WAV}\")\n",
    "print(f\"Duration: {len(audio)/1000:.1f} seconds\")\n",
    "print(\"\\nğŸ”Š Preview:\")\n",
    "display(Audio(SPEAKER_WAV))"
   ],
   "metadata": {
    "id": "create_sample_voice"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 4. OR Upload Your Own Voice Sample { display-mode: \"form\" }\n",
    "#@markdown Upload 6-30 seconds of clear speech (WAV/MP3).\n",
    "#@markdown **Skip this if you used the sample voice above.**\n",
    "\n",
    "from google.colab import files\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(\"Select your voice sample file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    SPEAKER_WAV = list(uploaded.keys())[0]\n",
    "    print(f\"\\nâœ… Using: {SPEAKER_WAV}\")\n",
    "    display(Audio(SPEAKER_WAV))\n",
    "else:\n",
    "    print(\"No file uploaded. Using previous sample voice.\")"
   ],
   "metadata": {
    "id": "upload_voice"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 5. Load Model & Clone Voice { display-mode: \"form\" }\n",
    "import torch\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts\n",
    "\n",
    "print(\"Loading viXTTS model...\")\n",
    "\n",
    "config = XttsConfig()\n",
    "config.load_json(str(MODEL_DIR / \"config.json\"))\n",
    "\n",
    "model = Xtts.init_from_config(config)\n",
    "model.load_checkpoint(\n",
    "    config,\n",
    "    checkpoint_path=str(MODEL_DIR / \"model.pth\"),\n",
    "    vocab_path=str(MODEL_DIR / \"vocab.json\")\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print(f\"âœ… Model loaded on GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Running on CPU (will be slow)\")\n",
    "\n",
    "# Clone voice\n",
    "print(f\"\\nğŸ¤ Cloning voice from: {SPEAKER_WAV}\")\n",
    "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=SPEAKER_WAV)\n",
    "print(\"âœ… Voice cloned successfully!\")"
   ],
   "metadata": {
    "id": "load_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 6. Generate Vietnamese Audio (viXTTS) { display-mode: \"form\" }\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "from google.colab import files\n",
    "\n",
    "#@markdown ### Nháº­p vÄƒn báº£n tiáº¿ng Viá»‡t (10+ tá»« cho cháº¥t lÆ°á»£ng tá»‘t nháº¥t):\n",
    "text_vi = \"Xin chÃ o cÃ¡c báº¡n, Ä‘Ã¢y lÃ  giá»ng nÃ³i cá»§a tÃ´i Ä‘Æ°á»£c táº¡o báº±ng trÃ­ tuá»‡ nhÃ¢n táº¡o. CÃ´ng nghá»‡ nÃ y cho phÃ©p clone giá»ng nÃ³i chá»‰ vá»›i má»™t Ä‘oáº¡n audio ngáº¯n.\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Settings:\n",
    "temperature = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
    "output_file = \"vixtts_output_vi.wav\" #@param {type:\"string\"}\n",
    "\n",
    "print(f\"Generating: {text_vi[:50]}...\\n\")\n",
    "\n",
    "out = model.inference(\n",
    "    text_vi,\n",
    "    \"vi\",\n",
    "    gpt_cond_latent,\n",
    "    speaker_embedding,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "sf.write(output_file, out[\"wav\"], 24000)\n",
    "\n",
    "print(f\"âœ… Generated: {output_file}\")\n",
    "print(\"\\nğŸ”Š Playback:\")\n",
    "display(Audio(output_file))\n",
    "\n",
    "print(\"\\nğŸ“¥ Downloading...\")\n",
    "files.download(output_file)"
   ],
   "metadata": {
    "id": "vixtts_generate_vi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 7. Generate English Audio (viXTTS) { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ### Enter English text:\n",
    "text_en = \"Welcome to The Lost Chapter. This is my voice, cloned using artificial intelligence. The technology allows creating natural sounding speech from just a short audio sample.\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Settings:\n",
    "temp_en = 0.7 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
    "output_en = \"vixtts_output_en.wav\" #@param {type:\"string\"}\n",
    "\n",
    "print(f\"Generating: {text_en[:50]}...\\n\")\n",
    "\n",
    "out_en = model.inference(\n",
    "    text_en,\n",
    "    \"en\",\n",
    "    gpt_cond_latent,\n",
    "    speaker_embedding,\n",
    "    temperature=temp_en\n",
    ")\n",
    "\n",
    "sf.write(output_en, out_en[\"wav\"], 24000)\n",
    "\n",
    "print(f\"âœ… Generated: {output_en}\")\n",
    "display(Audio(output_en))\n",
    "files.download(output_en)"
   ],
   "metadata": {
    "id": "vixtts_generate_en"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title 8. Batch Generate - Audiobook Chapter (viXTTS) { display-mode: \"form\" }\n",
    "import numpy as np\n",
    "\n",
    "#@markdown ### Nháº­p nhiá»u Ä‘oáº¡n vÄƒn:\n",
    "batch_text = \"\"\"ChÆ°Æ¡ng má»™t: HÃ nh trÃ¬nh báº¯t Ä‘áº§u.\n",
    "\n",
    "NgÃ y xÆ°a, á»Ÿ má»™t vÆ°Æ¡ng quá»‘c xa xÃ´i, cÃ³ má»™t chÃ ng trai tráº» tÃªn lÃ  Minh. Minh luÃ´n mÆ¡ Æ°á»›c Ä‘Æ°á»£c khÃ¡m phÃ¡ tháº¿ giá»›i rá»™ng lá»›n bÃªn ngoÃ i ngÃ´i lÃ ng nhá» cá»§a mÃ¬nh.\n",
    "\n",
    "Má»™t ngÃ y ná», khi máº·t trá»i vá»«a lÃ³ dáº¡ng, Minh quyáº¿t Ä‘á»‹nh lÃªn Ä‘Æ°á»ng. ChÃ ng mang theo má»™t chiáº¿c ba lÃ´ nhá» chá»©a Ä‘áº§y hy vá»ng vÃ  nhá»¯ng giáº¥c mÆ¡ chÆ°a thÃ nh hiá»‡n thá»±c.\n",
    "\n",
    "Con Ä‘Æ°á»ng phÃ­a trÆ°á»›c dÃ i vÃ  Ä‘áº§y thá»­ thÃ¡ch, nhÆ°ng Minh khÃ´ng há» sá»£ hÃ£i. ChÃ ng biáº¿t ráº±ng má»—i bÆ°á»›c chÃ¢n Ä‘á»u Ä‘Æ°a mÃ¬nh Ä‘áº¿n gáº§n hÆ¡n vá»›i sá»‘ pháº­n cá»§a chÃ­nh mÃ¬nh.\"\"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Settings:\n",
    "batch_lang = \"vi\" #@param [\"vi\", \"en\"]\n",
    "batch_output = \"chapter_audio.wav\" #@param {type:\"string\"}\n",
    "\n",
    "paragraphs = [p.strip() for p in batch_text.split('\\n\\n') if p.strip()]\n",
    "print(f\"ğŸ“– Found {len(paragraphs)} paragraphs\\n\")\n",
    "\n",
    "all_audio = []\n",
    "silence = np.zeros(int(24000 * 0.7))  # 0.7s pause\n",
    "\n",
    "for i, para in enumerate(paragraphs):\n",
    "    print(f\"[{i+1}/{len(paragraphs)}] {para[:45]}...\")\n",
    "    out = model.inference(\n",
    "        para,\n",
    "        batch_lang,\n",
    "        gpt_cond_latent,\n",
    "        speaker_embedding,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    all_audio.append(out[\"wav\"])\n",
    "    if i < len(paragraphs) - 1:\n",
    "        all_audio.append(silence)\n",
    "\n",
    "combined = np.concatenate(all_audio)\n",
    "sf.write(batch_output, combined, 24000)\n",
    "\n",
    "duration = len(combined) / 24000\n",
    "print(f\"\\nâœ… Generated: {batch_output}\")\n",
    "print(f\"â±ï¸ Duration: {duration:.1f} seconds ({duration/60:.1f} minutes)\")\n",
    "display(Audio(batch_output))\n",
    "files.download(batch_output)"
   ],
   "metadata": {
    "id": "vixtts_batch"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‹ Tips & Troubleshooting\n",
    "\n",
    "### Vietnamese Quality (viXTTS)\n",
    "- Use sentences with **10+ words** for best results\n",
    "- Shorter sentences may produce odd trailing sounds\n",
    "- Temperature 0.6-0.8 works best\n",
    "\n",
    "### Voice Sample Requirements\n",
    "- **6-30 seconds** of clear speech\n",
    "- No background noise/music\n",
    "- Natural speaking pace\n",
    "- WAV format preferred\n",
    "\n",
    "### Temperature Settings\n",
    "| Value | Result |\n",
    "|-------|--------|\n",
    "| 0.3-0.5 | Very consistent, robotic |\n",
    "| 0.6-0.7 | Natural, stable |\n",
    "| 0.8-0.9 | Expressive, varied |\n",
    "| 1.0+ | Unstable, experimental |\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**\"No GPU available\"**\n",
    "â†’ Go to Runtime > Change runtime type > T4 GPU\n",
    "\n",
    "**\"CUDA out of memory\"**\n",
    "â†’ Runtime > Restart runtime, then run again\n",
    "\n",
    "**Audio sounds robotic**\n",
    "â†’ Increase temperature to 0.8\n",
    "â†’ Use longer sentences\n",
    "\n",
    "**Edge TTS not working**\n",
    "â†’ Try different voice option\n",
    "â†’ Check internet connection\n",
    "\n",
    "### Supported Languages (viXTTS)\n",
    "ğŸ‡»ğŸ‡³ Vietnamese, ğŸ‡ºğŸ‡¸ English, ğŸ‡ªğŸ‡¸ Spanish, ğŸ‡«ğŸ‡· French, ğŸ‡©ğŸ‡ª German, ğŸ‡®ğŸ‡¹ Italian, ğŸ‡µğŸ‡¹ Portuguese, ğŸ‡µğŸ‡± Polish, ğŸ‡¹ğŸ‡· Turkish, ğŸ‡·ğŸ‡º Russian, ğŸ‡³ğŸ‡± Dutch, ğŸ‡¨ğŸ‡¿ Czech, ğŸ‡¸ğŸ‡¦ Arabic, ğŸ‡¨ğŸ‡³ Chinese, ğŸ‡¯ğŸ‡µ Japanese, ğŸ‡­ğŸ‡º Hungarian, ğŸ‡°ğŸ‡· Korean, ğŸ‡®ğŸ‡³ Hindi\n",
    "\n",
    "---\n",
    "\n",
    "**TheLostChapter** | [GitHub](https://github.com/nmnhut-it/english-learning-app/tree/main/the-lost-chapter) | [viXTTS Demo](https://huggingface.co/spaces/thinhlpg/vixtts-demo)"
   ],
   "metadata": {
    "id": "tips"
   }
  }
 ]
}